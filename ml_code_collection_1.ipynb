{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFTyTckWHGfodYQWoXXOVB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amarsinh0/MY-NOTES/blob/main/ml_code_collection_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing Necessary Libraries**"
      ],
      "metadata": {
        "id": "YmQoDl5f5VJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hello world\")"
      ],
      "metadata": {
        "id": "PKzIhqQlGfP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "briy7qUm4Y9c"
      },
      "outputs": [],
      "source": [
        "# Importing Necessary Libraries\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "sns.set(context=\"notebook\", palette=\"Spectral\", style = 'darkgrid' ,font_scale = 1.5, color_codes=True)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "'''\n",
        "This code is used to import the Seaborn library, which is a popular data visualization library in Python.\n",
        "\n",
        "The line `sns.set(context=\"notebook\", palette=\"Spectral\", style='darkgrid', font_scale=1.5, color_codes=True)`\n",
        "sets some default styling options for the plots created using Seaborn.\n",
        "\n",
        "- `context=\"notebook\"` sets the plotting context to \"notebook\",\n",
        "   which adjusts the size and scale of the plots to fit nicely within a notebook.\n",
        "- `palette=\"Spectral\"` sets the color palette to \"Spectral\", which determines the colors used in the plots.\n",
        "- `style='darkgrid'` sets the grid style to \"darkgrid\", which adds a dark background grid to the plots.\n",
        "- `font_scale=1.5` sets the scaling factor for the font size in the plots to 1.5 times the default size.\n",
        "- `color_codes=True` allows the usage of color codes in the plots.\n",
        "\n",
        "The next two lines import the `warnings` module and suppress any warning messages that might be generated during the code execution.\n",
        "\n",
        "The final line imports the `os` module, which provides a way to interact with the operating system.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the relationship between the features and the response using scatterplots\n",
        "p = sns.pairplot(ad_data, x_vars=['TV','Radio','Newspaper'], y_vars='Sales', size=7, aspect=0.7)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "This code uses Seaborn to create scatterplots that visualize the relationship between certain features and\n",
        " the response variable. Here's a breakdown of the code:\n",
        "\n",
        "- `p = sns.pairplot(ad_data, x_vars=['TV','Radio','Newspaper'], y_vars='Sales', size=7, aspect=0.7)`\n",
        "\n",
        "   - `sns.pairplot()` is a function in Seaborn that creates a grid of scatterplots.\n",
        "     It plots the relationship between multiple pairs of variables.\n",
        "   - `ad_data` is the dataset or dataframe containing the data.\n",
        "   - `x_vars=['TV','Radio','Newspaper']` specifies the features or independent variables (TV, Radio, and Newspaper)\n",
        "    to be plotted on the x-axis.\n",
        "   - `y_vars='Sales'` specifies the response variable or dependent variable (Sales) to be plotted on the y-axis.\n",
        "   - `size=7` sets the size of each subplot to 7 inches.\n",
        "   - `aspect=0.7` sets the aspect ratio of each subplot to 0.7.\n",
        "\n",
        "After executing this code, the variable `p` will hold the pairplot object,\n",
        "which can be used to further customize or analyze the plot if needed.\n",
        " The resulting scatterplots will show how the features (TV, Radio, and Newspaper) relate to the response variable (Sales).\n",
        " Each scatterplot will display the relationship between one of the features and the sales data.\n",
        " ,,,"
      ],
      "metadata": {
        "id": "e0QqTp526Hrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get dependent and independent variables - X and y\n",
        "\n",
        "X = ad_data.drop([\"Sales\"],axis=1)\n",
        "y = ad_data.Sales\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Certainly! This code is used to separate the dependent variable (y) from the independent variables (X) in a dataset.\n",
        "Here's a simplified explanation:\n",
        "\n",
        "- `X = ad_data.drop([\"Sales\"],axis=1)`\n",
        "\n",
        "   - `ad_data` is the dataset that contains the information.\n",
        "   - `drop([\"Sales\"], axis=1)` removes the \"Sales\" column from the dataset,\n",
        "   creating a new DataFrame `X` that contains all the remaining columns. In other words,\n",
        "    it extracts all the independent variables from the dataset.\n",
        "\n",
        "- `y = ad_data.Sales`\n",
        "\n",
        "   - `ad_data` is the dataset that contains the information.\n",
        "   - `ad_data.Sales` selects the \"Sales\" column from the dataset and assigns it to the variable `y`.\n",
        "    This column represents the dependent variable.\n",
        "\n",
        "After executing this code, you will have the independent variables stored in the DataFrame `X`,\n",
        "which includes all the columns of `ad_data` except for the \"Sales\" column. The dependent variable will be stored in the variable `y`,\n",
        "which contains the \"Sales\" column.\n",
        "This separation allows you to use the independent variables `X` to predict or explain the dependent variable `y` in a machine learning\n",
        " or statistical analysis context.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QwgL3qvb7FwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 0,test_size=0.25)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Certainly! This code is used to split the data into training and testing sets. Here's a simplified explanation:\n",
        "\n",
        "- `from sklearn.model_selection import train_test_split`\n",
        "\n",
        "   - This line imports the `train_test_split` function from the `model_selection` module of the `sklearn` (scikit-learn) library.\n",
        "    This function is used to split data into training and testing sets.\n",
        "\n",
        "- `X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)`\n",
        "\n",
        "   - `X` represents the independent variables (features) of the dataset.\n",
        "   - `y` represents the dependent variable (response) of the dataset.\n",
        "   - `random_state=0` sets a specific random seed to ensure reproducibility.\n",
        "   This means that the same random splitting of the data will be performed every time the code is run with this value.\n",
        "   - `test_size=0.25` specifies that 25% of the data will be allocated for testing, while the remaining 75% will be used for training.\n",
        "   - `X_train` and `y_train` will contain the training set for the independent and dependent variables, respectively.\n",
        "   - `X_test` and `y_test` will contain the testing set for the independent and dependent variables, respectively.\n",
        "\n",
        "After executing this code, the dataset will be split into training and testing sets.\n",
        " The training sets (`X_train` and `y_train`) will be used to train a machine learning model,\n",
        " while the testing sets (`X_test` and `y_test`) will be used to evaluate the model's performance.\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "Dxb6au0H77XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the linear regression model\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn import linear_model\n",
        "\n",
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(X_train,y_train)\n",
        "y_pred = regr.predict(X_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Certainly! This code is used to fit a linear regression model to the training data and make predictions. Here's a detailed explanation:\n",
        "\n",
        "- `from sklearn.metrics import mean_absolute_error`\n",
        "- `from sklearn.metrics import mean_squared_error`\n",
        "- `from sklearn.metrics import r2_score`\n",
        "- `from sklearn import linear_model`\n",
        "\n",
        "   - These lines import necessary modules and functions from scikit-learn (`sklearn`) library.\n",
        "   These modules and functions will be used to evaluate the performance of the linear regression model.\n",
        "\n",
        "- `regr = linear_model.LinearRegression()`\n",
        "\n",
        "   - This line creates an instance of the `LinearRegression` class from the `linear_model` module.\n",
        "   This class represents the linear regression model.\n",
        "\n",
        "- `regr.fit(X_train, y_train)`\n",
        "\n",
        "   - This line fits (trains) the linear regression model using the training data (`X_train` and `y_train`).\n",
        "    It calculates the coefficients (weights) that best fit the data.\n",
        "\n",
        "- `y_pred = regr.predict(X_train)`\n",
        "\n",
        "   - This line uses the trained linear regression model to make predictions on the training data (`X_train`).\n",
        "    The predicted values are stored in the variable `y_pred`.\n",
        "\n",
        "After executing this code, you will have a trained linear regression model (`regr`) that\n",
        "has learned the relationship between the independent variables (`X_train`) and the dependent variable (`y_train`).\n",
        "Additionally, the predicted values (`y_pred`) are obtained based on the model's learned coefficients.\n",
        "\n",
        "The imported metrics (`mean_absolute_error`, `mean_squared_error`, and `r2_score`) can be used to evaluate the performance\n",
        " of the model by comparing the predicted values (`y_pred`) with the actual values (`y_train`).\n",
        " These metrics provide information about the accuracy, error, and explained variance of the model.\n",
        " \"\"\"\n",
        "\n",
        "\n",
        "\n",
        " # Use MSE to evaluate the above model(assignment)\n",
        "print(\"R squared: {}\".format(r2_score(y_true=y_train,y_pred=y_pred)))\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Certainly! In this code, the mean squared error (MSE) metric is used to evaluate the performance of the linear regression model.\n",
        " Here's a detailed explanation:\n",
        "\n",
        "- `r2_score(y_true=y_train, y_pred=y_pred)`\n",
        "\n",
        "   - This line calculates the R-squared score, also known as the coefficient of determination,\n",
        "   which measures how well the linear regression model fits the training data.\n",
        "\n",
        "   - `y_true` represents the true values or actual values of the dependent variable (`y_train`).\n",
        "   - `y_pred` represents the predicted values of the dependent variable obtained from the linear regression model.\n",
        "\n",
        "- `print(\"R squared: {}\".format(r2_score(y_true=y_train, y_pred=y_pred)))`\n",
        "\n",
        "   - This line prints the R-squared score to the console using the `print()` function.\n",
        "\n",
        "   - `\"R squared: {}\"` is a formatted string that includes a placeholder `{}` where the value of the R-squared score will be inserted.\n",
        "   - `format(r2_score(y_true=y_train, y_pred=y_pred))` fills in the placeholder with the calculated R-squared score.\n",
        "\n",
        "The R-squared score ranges from 0 to 1, where 1 indicates a perfect fit of the model to the data, and 0 indicates that\n",
        " the model does not explain any of the variation in the data.\n",
        "\n",
        "By printing the R-squared score, you can assess how well the linear regression\n",
        " model performs in explaining the variability of the dependent variable (`y_train`) based on the\n",
        " independent variables (`X_train`). A higher R-squared score indicates that the model captures a larger proportion of the\n",
        "  variation in the training data, suggesting a better fit.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WkWr9qDx8eD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Mean of Residuals**"
      ],
      "metadata": {
        "id": "j3xmBcka9-lW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = y_train.values-y_pred\n",
        "mean_residuals = np.mean(residuals)\n",
        "print(\"Mean of Residuals {}\".format(mean_residuals))\n",
        "\n",
        "Mean of Residuals -4.073778351691241e-15\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Certainly! This code calculates the mean of the residuals, which are the differences between\n",
        "the actual values and the predicted values of the dependent variable in a linear regression model. Here's a simplified explanation:\n",
        "\n",
        "- `residuals = y_train.values - y_pred`\n",
        "\n",
        "   - This line calculates the residuals by subtracting the predicted values (`y_pred`) from\n",
        "   the actual values (`y_train`) of the dependent variable. It represents the differences between\n",
        "   the observed values and the values predicted by the linear regression model.\n",
        "\n",
        "- `mean_residuals = np.mean(residuals)`\n",
        "\n",
        "   - This line calculates the mean of the residuals using the `np.mean()` function from the NumPy library.\n",
        "   It computes the average of all the residual values.\n",
        "\n",
        "- `print(\"Mean of Residuals {}\".format(mean_residuals))`\n",
        "\n",
        "   - This line prints the mean of the residuals to the console using the `print()` function.\n",
        "\n",
        "   - `\"Mean of Residuals {}\"` is a formatted string that includes a placeholder `{}` where\n",
        "   the value of the mean of the residuals will be inserted.\n",
        "   - `format(mean_residuals)` fills in the placeholder with the calculated mean of the residuals.\n",
        "\n",
        "The mean of the residuals represents the average deviation between the observed values and the predicted values.\n",
        "Ideally, this value should be close to zero. If the mean of the residuals is significantly different from zero,\n",
        " it suggests that the linear regression model has a systematic bias in its predictions.\n",
        "\n",
        "In the specific example you provided, the mean of the residuals is approximately -4.07 x 10^(-15),\n",
        " which is very close to zero. This indicates that, on average,\n",
        " the linear regression model's predictions are very close to the actual values of the dependent variable in the training data.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "odgKcsyF9v79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Check for Homoscedasticity**"
      ],
      "metadata": {
        "id": "pVZ77RMy_G7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Detecting heteroscedasticity!**"
      ],
      "metadata": {
        "id": "_MsBUHsp_LL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = sns.scatterplot(y_pred,residuals)\n",
        "plt.xlabel('y_pred/predicted values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.ylim(-10,10)\n",
        "plt.xlim(0,26)\n",
        "p = sns.lineplot([0,26],[0,0],color='blue')\n",
        "p = plt.title('Residuals vs fitted values plot for homoscedasticity check')\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This code is used to create a scatter plot to check for homoscedasticity,\n",
        "which is the assumption in linear regression that the variance of the residuals should be\n",
        "constant across different levels of the predicted values. Here's a breakdown of the code:\n",
        "\n",
        "- `p = sns.scatterplot(y_pred, residuals)`\n",
        "\n",
        "   - This line creates a scatter plot using the Seaborn library. The predicted values (`y_pred`) are plotted on the x-axis,\n",
        "   and the residuals (the differences between the actual values and predicted values) are plotted on the y-axis.\n",
        "\n",
        "- `plt.xlabel('y_pred/predicted values')`\n",
        "\n",
        "   - This line sets the label for the x-axis as \"y_pred/predicted values\".\n",
        "\n",
        "- `plt.ylabel('Residuals')`\n",
        "\n",
        "   - This line sets the label for the y-axis as \"Residuals\".\n",
        "\n",
        "- `plt.ylim(-10, 10)`\n",
        "\n",
        "   - This line sets the y-axis limits from -10 to 10, controlling the range of the y-axis in the plot.\n",
        "\n",
        "- `plt.xlim(0, 26)`\n",
        "\n",
        "   - This line sets the x-axis limits from 0 to 26, controlling the range of the x-axis in the plot.\n",
        "\n",
        "- `p = sns.lineplot([0, 26], [0, 0], color='blue')`\n",
        "\n",
        "   - This line adds a horizontal line at y=0 using the `lineplot` function from Seaborn.\n",
        "   The line represents the zero-error or the perfect fit line.\n",
        "\n",
        "- `p = plt.title('Residuals vs fitted values plot for homoscedasticity check')`\n",
        "\n",
        "   - This line sets the title of the plot as \"Residuals vs fitted values plot for homoscedasticity check\".\n",
        "\n",
        "The scatter plot allows us to visually inspect the relationship between the predicted values and the residuals.\n",
        "If the plot exhibits a random scattering of points around the zero-error line,\n",
        "it suggests that the assumption of homoscedasticity is met. In other words,\n",
        "the variance of the residuals is relatively constant across different levels of the predicted values.\n",
        "\n",
        "The code also sets the labels, limits, and title of the plot to provide clear and informative visualization\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rBSUJrDj-73c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goldfeld Quandt Test**"
      ],
      "metadata": {
        "id": "bZdZ_JYxASfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.stats.api as sms\n",
        "from statsmodels.compat import lzip\n",
        "name = ['F statistic', 'p-value']\n",
        "test = sms.het_goldfeldquandt(residuals, X_train)\n",
        "lzip(name, test)\n",
        "[('F statistic', 1.1098849261262689), ('p-value', 0.3297188431941372)]\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This code uses the `statsmodels` library to perform the Goldfeld-Quandt test for heteroscedasticity. Here's a breakdown of the code:\n",
        "\n",
        "- `import statsmodels.stats.api as sms`\n",
        "   - This line imports the `statsmodels.stats.api` module from the `statsmodels` library.\n",
        "   This module provides statistical tests and functions for hypothesis testing.\n",
        "\n",
        "- `from statsmodels.compat import lzip`\n",
        "   - This line imports the `lzip` function from the `statsmodels.compat` module.\n",
        "   `lzip` is used to combine multiple sequences into a list of tuples.\n",
        "\n",
        "- `name = ['F statistic', 'p-value']`\n",
        "   - This line creates a list named `name` that contains the names of the test statistics we are interested in.\n",
        "\n",
        "- `test = sms.het_goldfeldquandt(residuals, X_train)`\n",
        "   - This line performs the Goldfeld-Quandt test for heteroscedasticity using the `het_goldfeldquandt` function\n",
        "   from `statsmodels.stats.api`. It takes two arguments: the residuals (the differences between the actual values and predicted values)\n",
        "    and the independent variable (`X_train`).\n",
        "\n",
        "- `lzip(name, test)`\n",
        "   - This line combines the elements of the `name` list and the `test` results into a\n",
        "    list of tuples using the `lzip` function. Each tuple contains the name of a test statistic and its corresponding value.\n",
        "\n",
        "The Goldfeld-Quandt test is used to check for heteroscedasticity, which is the violation of the assumption that the\n",
        "variance of the residuals is constant across different levels of the independent variable.\n",
        " By performing this test, we can assess whether there is evidence of heteroscedasticity in the model.\n",
        "\n",
        "The result of `lzip(name, test)` will provide a list of tuples where each tuple\n",
        "contains the name of a test statistic (`'F statistic'` and `'p-value'`) and its corresponding value.\n",
        "The F statistic is a measure of the difference in variance between two subsets of the data, and\n",
        "the p-value indicates the statistical significance of the test.\n",
        "The output `[('F statistic', 1.1098849261262689), ('p-value', 0.3297188431941372)]` indicates the results of the Goldfeld-Quandt test\n",
        "for heteroscedasticity. Here's the breakdown of the output:\n",
        "\n",
        "- `('F statistic', 1.1098849261262689)`: This tuple represents the F statistic, which is a measure of\n",
        " the difference in variance between two subsets of the data. In this case, the computed F statistic is approximately 1.1098849261262689.\n",
        "\n",
        "- `('p-value', 0.3297188431941372)`: This tuple represents the p-value, which is a measure of the\n",
        "statistical significance of the test. In this case, the computed p-value is approximately 0.3297188431941372.\n",
        "\n",
        "The F statistic is used to compare the variances of the residuals between two subsets of the data,\n",
        "usually based on the order of the observations. A higher F statistic suggests greater evidence of heteroscedasticity.\n",
        "\n",
        "The p-value indicates the probability of observing the given test statistic (or more extreme) under\n",
        "the null hypothesis. In this case, a p-value of 0.3297188431941372 suggests that there is no strong\n",
        "evidence to reject the null hypothesis of homoscedasticity. However, the interpretation of the p-value depends\n",
        " on the chosen significance level (typically 0.05).\n",
        "\n",
        "Overall, based on the given output, there is no strong evidence to suggest heteroscedasticity in the model,\n",
        "as the F statistic is relatively low and the p-value is greater than the typical significance level of 0.05.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "X3S15zh9AVJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4) Check for Normality of error terms/residuals**"
      ],
      "metadata": {
        "id": "J2NbYyuiB1Iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Check for Normality of error terms/residuals\n",
        "\n",
        "p = sns.distplot(residuals,kde=True)\n",
        "p = plt.title('Normality of error terms/residuals')\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "This code checks for the normality of error terms or residuals in a linear regression model. Here's a breakdown of the code:\n",
        "\n",
        "- `p = sns.distplot(residuals, kde=True)`\n",
        "\n",
        "   - This line uses Seaborn's `distplot` function to create a histogram and a kernel density estimation (KDE) plot of the residuals.\n",
        "   The residuals are passed as the input to the function.\n",
        "\n",
        "   - The histogram represents the distribution of the residuals, while the KDE plot provides a smoothed estimate of the\n",
        "   underlying probability density function.\n",
        "\n",
        "- `p = plt.title('Normality of error terms/residuals')`\n",
        "\n",
        "   - This line sets the title of the plot as \"Normality of error terms/residuals\" using the `title` function from Matplotlib.\n",
        "\n",
        "The purpose of this code is to visually assess the normality assumption of the error terms or residuals in\n",
        " a linear regression model. The assumption states that the error terms should follow a normal distribution,\n",
        " which is important for the validity of statistical inference and hypothesis testing.\n",
        "\n",
        "By plotting the histogram and KDE plot, you can visually inspect the shape of the distribution of the residuals.\n",
        " If the distribution appears to be approximately symmetrical and bell-shaped, it suggests that the assumption of normality is met.\n",
        " However, if the distribution is skewed or has unusual patterns, it indicates a departure from normality.\n",
        "\n",
        "The plot provides a visual representation of the normality assumption, allowing you to assess whether the error terms\n",
        " in the linear regression model follow a normal distribution.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "y_sjNtsXBRtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. No autocorrelation of residuals**"
      ],
      "metadata": {
        "id": "UVX9io4eCEtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "p = sns.lineplot(y_pred,residuals,marker='o',color='blue')\n",
        "plt.xlabel('y_pred/predicted values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.ylim(-10,10)\n",
        "plt.xlim(0,26)\n",
        "p = sns.lineplot([0,26],[0,0],color='red')\n",
        "p = plt.title('Residuals vs fitted values plot for autocorrelation check')\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This code creates a line plot to check for autocorrelation in the residuals of a linear regression model. Here's a breakdown of the code:\n",
        "\n",
        "- `plt.figure(figsize=(10,5))`\n",
        "   - This line sets the figure size of the plot to (10,5) using the `figure` function from Matplotlib.\n",
        "    This ensures that the plot has specific dimensions.\n",
        "\n",
        "- `p = sns.lineplot(y_pred, residuals, marker='o', color='blue')`\n",
        "   - This line creates a line plot using Seaborn's `lineplot` function.\n",
        "   It plots the residuals on the y-axis and the predicted values (`y_pred`) on the x-axis.\n",
        "    Each point in the plot is represented by a marker ('o').\n",
        "\n",
        "- `plt.xlabel('y_pred/predicted values')`\n",
        "   - This line sets the x-axis label as \"y_pred/predicted values\" using the `xlabel` function from Matplotlib.\n",
        "\n",
        "- `plt.ylabel('Residuals')`\n",
        "   - This line sets the y-axis label as \"Residuals\" using the `ylabel` function from Matplotlib.\n",
        "\n",
        "- `plt.ylim(-10, 10)`\n",
        "   - This line sets the y-axis limits from -10 to 10, controlling the range of the y-axis in the plot.\n",
        "\n",
        "- `plt.xlim(0, 26)`\n",
        "   - This line sets the x-axis limits from 0 to 26, controlling the range of the x-axis in the plot.\n",
        "\n",
        "- `p = sns.lineplot([0, 26], [0, 0], color='red')`\n",
        "   - This line adds a horizontal line at y=0 using the `lineplot` function from Seaborn.\n",
        "   The line represents the zero-error or the perfect fit line.\n",
        "\n",
        "- `p = plt.title('Residuals vs fitted values plot for autocorrelation check')`\n",
        "   - This line sets the title of the plot as \"Residuals vs fitted values plot for\n",
        "   autocorrelation check\" using the `title` function from Matplotlib.\n",
        "\n",
        "The purpose of this code is to visually assess whether there is any autocorrelation (correlation between residuals at different points in time)\n",
        " in the linear regression model. The plot allows you to examine the pattern and distribution of the residuals relative to the predicted values.\n",
        "  If there is no autocorrelation, the residuals should be randomly scattered around the zero-error line.\n",
        "\n",
        "The code sets the labels, limits, and title of the plot to provide clear and informative visualization.\n",
        "The figure size is also adjusted to control the dimensions of the plot.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TLrrSAv_CIRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#minimum p-value from the Ljung-Box test for autocorrelation in the residuals of a linear regression model.\n",
        "\n",
        "from statsmodels.stats import diagnostic as diag\n",
        "min(diag.acorr_ljungbox(residuals , lags = 40)[1])\n",
        "\n",
        "0.008425577339963797\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code you provided calculates the minimum p-value from the Ljung-Box test for\n",
        "autocorrelation in the residuals of a linear regression model. Here's a breakdown of the code:\n",
        "\n",
        "- `from statsmodels.stats import diagnostic as diag`\n",
        "   - This line imports the `diagnostic` module from the `statsmodels.stats` package.\n",
        "   This module provides statistical tests and diagnostics for model evaluation.\n",
        "\n",
        "- `min(diag.acorr_ljungbox(residuals, lags=40)[1])`\n",
        "   - This line performs the Ljung-Box test for autocorrelation using the `acorr_ljungbox` function\n",
        "   from `statsmodels.stats.diagnostic`. It takes the residuals as input and specifies the number of lags to consider (in this case, 40).\n",
        "\n",
        "   - `diag.acorr_ljungbox(residuals, lags=40)` calculates the Ljung-Box test statistic and\n",
        "    p-values for each lag up to the specified number of lags.\n",
        "\n",
        "   - `[1]` extracts the array of p-values from the Ljung-Box test result.\n",
        "\n",
        "   - `min(...)` finds the minimum value from the array of p-values.\n",
        "\n",
        "The Ljung-Box test is used to test for the presence of autocorrelation in the\n",
        "residuals of a time series or regression model. The null hypothesis of the test is\n",
        "that there is no autocorrelation. A low p-value (typically below a significance level, such as 0.05)\n",
        "suggests evidence of autocorrelation, indicating that the null hypothesis is rejected.\n",
        "\n",
        "In the specific code you provided, the minimum p-value from the Ljung-Box test is approximately 0.008425577339963797.\n",
        " This suggests that there is evidence of autocorrelation in the residuals, as the p-value is lower than a typical significance level of 0.05.\n",
        " \"\"\"\n"
      ],
      "metadata": {
        "id": "P1BiPSS3Csfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "# autocorrelation\n",
        "sm.graphics.tsa.plot_acf(residuals, lags=40)\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "This code uses the `statsmodels` library to plot the autocorrelation function (ACF) of the residuals from a linear regression model.\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "- `import statsmodels.api as sm`\n",
        "   - This line imports the `statsmodels.api` module, which provides a wide range of statistical models and functions.\n",
        "\n",
        "- `sm.graphics.tsa.plot_acf(residuals, lags=40)`\n",
        "   - This line calls the `plot_acf` function from the `tsa` module in `statsmodels.graphics`.\n",
        "   It takes the residuals as input and specifies the number of lags to include in the ACF plot (in this case, 40).\n",
        "\n",
        "- `plt.show()`\n",
        "   - This line displays the ACF plot using the `show` function from the Matplotlib library.\n",
        "   It shows the plot in a separate window or cell output.\n",
        "\n",
        "The ACF plot visualizes the autocorrelation of the residuals at different lags.\n",
        "Autocorrelation measures the relationship between a variable and its lagged values.\n",
        " In this case, the residuals are used to examine the correlation between the residuals at different time points.\n",
        "\n",
        "The ACF plot displays bars or lines indicating the strength of autocorrelation at each lag.\n",
        " The y-axis represents the autocorrelation values, and the x-axis represents the lags.\n",
        " Positive or negative bars above or below the zero line indicate positive or negative autocorrelation, respectively.\n",
        "\n",
        "By plotting the ACF of the residuals, you can identify any significant autocorrelation patterns.\n",
        "This can help assess the presence of serial correlation in the residuals,\n",
        "which is important for the validity of statistical inference and model assumptions.\n",
        "\n",
        "Make sure you have the necessary libraries (`statsmodels` and `matplotlib`) imported before executing this code.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Q87n_CQKERDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Some other model evaluations**"
      ],
      "metadata": {
        "id": "g8rMmy5gEozW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "dec_tree = DecisionTreeRegressor(random_state=0)\n",
        "dec_tree.fit(X_train,y_train)\n",
        "dec_tree_y_pred = dec_tree.predict(X_train)\n",
        "print(\"Accuracy: {}\".format(dec_tree.score(X_train,y_train)))\n",
        "print(\"R squared: {}\".format(r2_score(y_true=y_train,y_pred=dec_tree_y_pred)))\n",
        "\n",
        "Accuracy: 1.0\n",
        "R squared: 1.0\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Certainly! The code you provided uses the scikit-learn library to train a Decision Tree Regressor model\n",
        " and evaluate its performance. Here's a detailed explanation:\n",
        "\n",
        "- `from sklearn.tree import DecisionTreeRegressor`\n",
        "  - This line imports the `DecisionTreeRegressor` class from the `tree` module in scikit-learn.\n",
        "  `DecisionTreeRegressor` is a class that represents a decision tree-based regression model.\n",
        "\n",
        "- `dec_tree = DecisionTreeRegressor(random_state=0)`\n",
        "  - This line creates an instance of the `DecisionTreeRegressor` class and assigns it to the variable `dec_tree`.\n",
        "   The `random_state=0` argument ensures reproducibility by setting a specific random seed.\n",
        "\n",
        "- `dec_tree.fit(X_train, y_train)`\n",
        "  - This line trains the decision tree regression model using the training data (`X_train` and `y_train`).\n",
        "  It fits the model to learn the relationship between the independent variables (`X_train`) and the dependent variable (`y_train`).\n",
        "\n",
        "- `dec_tree_y_pred = dec_tree.predict(X_train)`\n",
        "  - This line uses the trained decision tree model to make predictions on the training data (`X_train`).\n",
        "  The predicted values are stored in the variable `dec_tree_y_pred`.\n",
        "\n",
        "- `print(\"Accuracy: {}\".format(dec_tree.score(X_train, y_train)))`\n",
        "  - This line calculates and prints the accuracy score of the decision tree model on the training data.\n",
        "  The `score` method of the decision tree regressor calculates the coefficient of determination\n",
        "  (R-squared) of the predictions. The accuracy score ranges from 0 to 1, with a value of 1 indicating a perfect fit.\n",
        "\n",
        "- `print(\"R squared: {}\".format(r2_score(y_true=y_train, y_pred=dec_tree_y_pred)))`\n",
        "  - This line calculates and prints the R-squared score of the decision tree model on the training data.\n",
        "  The `r2_score` function from scikit-learn's metrics module calculates the R-squared score,\n",
        "   which measures the proportion of the variance in the dependent variable (`y_train`)\n",
        "   that is explained by the independent variables (`X_train`). A value of 1 indicates a perfect fit.\n",
        "\n",
        "The output of the code indicates the accuracy and R-squared score of the decision tree regression model on the training data.\n",
        " In this case, the model achieves an accuracy score of 1.0 and an R-squared score of 1.0,\n",
        "  which suggests that the model perfectly fits the training data. However,\n",
        "   it's important to note that achieving a perfect fit on the training data may indicate overfitting, and the model's\n",
        "   performance should be evaluated on unseen test data for a more reliable assessment.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "iFXEvYqqEesD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf_tree = RandomForestRegressor(random_state=0)\n",
        "rf_tree.fit(X_train,y_train)\n",
        "rf_tree_y_pred = rf_tree.predict(X_train)\n",
        "print(\"Accuracy: {}\".format(rf_tree.score(X_train,y_train)))\n",
        "print(\"R squared: {}\".format(r2_score(y_true=y_train,y_pred=rf_tree_y_pred)))\n",
        "\n",
        "\n",
        "Accuracy: 0.9969123907528763\n",
        "R squared: 0.9969123907528763\n",
        "\n",
        "\"\"\"\n",
        "The code you provided uses the scikit-learn library to train a Random Forest Regressor model and evaluate\n",
        "its performance. Here's a detailed explanation:\n",
        "\n",
        "- `from sklearn.ensemble import RandomForestRegressor`\n",
        "   - This line imports the `RandomForestRegressor` class from the `ensemble` module in scikit-learn.\n",
        "   `RandomForestRegressor` is a class that represents a random forest-based regression model.\n",
        "\n",
        "- `rf_tree = RandomForestRegressor(random_state=0)`\n",
        "   - This line creates an instance of the `RandomForestRegressor` class and assigns it to the variable `rf_tree`.\n",
        "    The `random_state=0` argument ensures reproducibility by setting a specific random seed.\n",
        "\n",
        "- `rf_tree.fit(X_train, y_train)`\n",
        "   - This line trains the random forest regression model using the training data (`X_train` and `y_train`).\n",
        "    It fits the model to learn the relationship between the independent variables (`X_train`) and the dependent variable (`y_train`).\n",
        "\n",
        "- `rf_tree_y_pred = rf_tree.predict(X_train)`\n",
        "   - This line uses the trained random forest model to make predictions on the training data (`X_train`).\n",
        "   The predicted values are stored in the variable `rf_tree_y_pred`.\n",
        "\n",
        "- `print(\"Accuracy: {}\".format(rf_tree.score(X_train, y_train)))`\n",
        "   - This line calculates and prints the accuracy score of the random forest model on the training data.\n",
        "    The `score` method of the random forest regressor calculates the coefficient of determination (R-squared) of the predictions.\n",
        "    The accuracy score ranges from 0 to 1, with a value of 1 indicating a perfect fit.\n",
        "\n",
        "- `print(\"R squared: {}\".format(r2_score(y_true=y_train, y_pred=rf_tree_y_pred)))`\n",
        "   - This line calculates and prints the R-squared score of the random forest model on the training data.\n",
        "   The `r2_score` function from scikit-learn's metrics module calculates the R-squared score,\n",
        "   which measures the proportion of the variance in the dependent variable (`y_train`)\n",
        "    that is explained by the independent variables (`X_train`).\n",
        "    A value of 1 indicates a perfect fit.\n",
        "\n",
        "The output of the code indicates the accuracy and R-squared score of the random forest regression model on the training data.\n",
        "In this case, the model achieves an accuracy score of 0.9969123907528763 and an R-squared score of 0.9969123907528763.\n",
        " These high scores suggest that the model fits the training data very well and explains\n",
        " a large proportion of the variance in the dependent variable.\n",
        "\n",
        "However, it's important to note that achieving high scores on the training data does not guarantee good performance on unseen test data.\n",
        " It's recommended to evaluate the model's performance on a separate test set to assess its generalization capability.\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "sOQNjXaiFa5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "svr = SVR()\n",
        "svr.fit(X_train,y_train)\n",
        "svr_y_pred = svr.predict(X_train)\n",
        "print(\"Accuracy: {}\".format(svr.score(X_train,y_train)))\n",
        "print(\"R squared: {}\".format(r2_score(y_true=y_train,y_pred=svr_y_pred)))\n",
        "\n",
        "Accuracy: 0.840786959997285\n",
        "R squared: 0.840786959997285\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code you provided uses the scikit-learn library to train a Support Vector Regressor (SVR) model\n",
        " and evaluate its performance. Here's a detailed explanation:\n",
        "\n",
        "- `from sklearn.svm import SVR`\n",
        "   - This line imports the `SVR` class from the `svm` module in scikit-learn. `SVR` is a\n",
        "   class that represents a support vector regression model.\n",
        "\n",
        "- `svr = SVR()`\n",
        "   - This line creates an instance of the `SVR` class and assigns it to the variable `svr`.\n",
        "    By default, this creates an SVR model with the default hyperparameters.\n",
        "\n",
        "- `svr.fit(X_train, y_train)`\n",
        "   - This line trains the SVR model using the training data (`X_train` and `y_train`).\n",
        "   It fits the model to learn the relationship between the independent variables (`X_train`)\n",
        "    and the dependent variable (`y_train`).\n",
        "\n",
        "- `svr_y_pred = svr.predict(X_train)`\n",
        "   - This line uses the trained SVR model to make predictions on the training data (`X_train`).\n",
        "   The predicted values are stored in the variable `svr_y_pred`.\n",
        "\n",
        "- `print(\"Accuracy: {}\".format(svr.score(X_train, y_train)))`\n",
        "   - This line calculates and prints the accuracy score of the SVR model on the training data.\n",
        "   The `score` method of the SVR model returns the coefficient of determination (R-squared) of the predictions.\n",
        "    The accuracy score ranges from -∞ to 1, with a value of 1 indicating a perfect fit.\n",
        "\n",
        "- `print(\"R squared: {}\".format(r2_score(y_true=y_train, y_pred=svr_y_pred)))`\n",
        "   - This line calculates and prints the R-squared score of the SVR model on the training data.\n",
        "\n",
        "   The `r2_score` function from scikit-learn's metrics module calculates the R-squared score,\n",
        "    which measures the proportion of the variance in the dependent variable (`y_train`) that is explained by\n",
        "     the independent variables (`X_train`). A value of 1 indicates a perfect fit.\n",
        "\n",
        "The output of the code indicates the accuracy and R-squared score of the SVR model on the training data.\n",
        " In this case, the model achieves an accuracy score of 0.840786959997285 and an R-squared score of 0.840786959997285.\n",
        "  These scores suggest that the SVR model has learned some of the underlying patterns in the training data and\n",
        "   can explain approximately 84% of the variance in the dependent variable.\n",
        "\n",
        "It's important to note that the interpretation of the accuracy and R-squared scores may depend on the\n",
        " specific context and the range of values of the dependent variable. Additionally, as with any model evaluation,\n",
        " it is recommended to assess the performance on unseen test data to get a more reliable estimation of the model's generalization capability.\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "mhP-mqG4G7Y9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}