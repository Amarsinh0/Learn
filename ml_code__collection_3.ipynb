{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOObNgIgfwvswd7LfMH0h7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amarsinh0/MY-NOTES/blob/main/ml_code__collection_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gTZdjL4Wp4qN"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\"\"\"\n",
        "The code `warnings.filterwarnings('ignore')` is used to suppress warning messages in the code execution.\n",
        "\n",
        "Warnings are informative messages that alert the user about potential issues or\n",
        "non-optimal practices in the code. They are intended to provide guidance and suggestions\n",
        " for improving code quality or avoiding potential problems. However, sometimes these warning\n",
        "messages can be excessive or unnecessary, especially in certain scenarios or when working with third-party libraries.\n",
        "\n",
        "By using `warnings.filterwarnings('ignore')`, the code instructs the Python interpreter to\n",
        "ignore any warning messages that may arise during the code execution. This ensures that the\n",
        "warnings will not be displayed in the console or interrupt the program flow. It can be useful\n",
        "when you are confident that the code is functioning correctly and you do not need to be alerted about the warnings.\n",
        "\n",
        "It is important to note that suppressing warnings should be done with caution. It is generally\n",
        "recommended to address and fix any issues or potential problems indicated by the warnings rather\n",
        "than ignoring them outright. Ignoring warnings without proper consideration may lead to unintended\n",
        "consequences or overlooking important aspects of the code.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **categoriacal varialble**"
      ],
      "metadata": {
        "id": "mv6cjuNFsBJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **find categorical variables**"
      ],
      "metadata": {
        "id": "SmGyHUP1qsuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find categorical variables\n",
        "\n",
        "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
        "\n",
        "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
        "\n",
        "print('The categorical variables are :', categorical)\n",
        "\n",
        "output:-\n",
        "\n",
        "There are 7 categorical variables\n",
        "\n",
        "The categorical variables are : ['Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code snippet is used to find and display the categorical variables in a DataFrame `df`.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "1. `categorical = [var for var in df.columns if df[var].dtype=='O']`:\n",
        "   - This line creates a list comprehension that iterates over the columns of the DataFrame `df`.\n",
        "   - For each column, it checks if the data type is `'O'`, which typically\n",
        "     represents object or string type columns (categorical variables).\n",
        "   - If the condition is met, the column name is added to the `categorical` list.\n",
        "\n",
        "2. `print('There are {} categorical variables\\n'.format(len(categorical)))`:\n",
        "   - This line prints the number of categorical variables found in the DataFrame using string formatting.\n",
        "   - The `len(categorical)` returns the length (number of elements) of the `categorical` list.\n",
        "   - The number is inserted into the string using `{}` as a placeholder, and `.format()`\n",
        "    is used to substitute the value into the string.\n",
        "\n",
        "3. `print('The categorical variables are :', categorical)`:\n",
        "   - This line prints the list of categorical variables found in the DataFrame.\n",
        "   - The list `categorical` is printed as is, displaying the names of the categorical variables.\n",
        "\n",
        "The output of this code will be the number of categorical variables found in\n",
        "the DataFrame `df` and the list of their names.\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "1lZZit23qei3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **# print categorical variables containing missing values**"
      ],
      "metadata": {
        "id": "xJtiFhNPryaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print categorical variables containing missing values\n",
        "\n",
        "cat1 = [var for var in categorical if df[var].isnull().sum()!=0]\n",
        "\n",
        "print(df[cat1].isnull().sum())\n",
        ""
      ],
      "metadata": {
        "id": "DUhBnFKwrR1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # view frequency of categorical variables\n",
        "\n",
        "for var in categorical:\n",
        "\n",
        "    print(df[var].value_counts())"
      ],
      "metadata": {
        "id": "pZmCOpuesOKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for cardinality in categorical variables\n",
        "\n",
        "for var in categorical:\n",
        "\n",
        "    print(var, ' contains ', len(df[var].unique()), ' labels')\n",
        "\n",
        "output:\n",
        "\n",
        "Date  contains  3436  labels\n",
        "Location  contains  49  labels"
      ],
      "metadata": {
        "id": "Wa4a1_0MsSed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering of Date Variable**"
      ],
      "metadata": {
        "id": "OKks66D8s0ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parse the dates, currently coded as strings, into datetime format\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "\n",
        "\n",
        "# extract year from date\n",
        "\n",
        "df['Year'] = df['Date'].dt.year\n",
        "\n",
        "df['Year'].head()\n",
        "\n",
        "output:\n",
        "\n",
        "0    2008\n",
        "1    2008\n",
        "2    2008\n",
        "3    2008\n",
        "4    2008\n",
        "Name: Year, dtype: int64\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# extract month from date\n",
        "\n",
        "df['Month'] = df['Date'].dt.month\n",
        "\n",
        "df['Month'].head()\n",
        "\n",
        "0    12\n",
        "1    12\n",
        "2    12\n",
        "3    12\n",
        "4    12"
      ],
      "metadata": {
        "id": "SKX-grtks7o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the original Date variable\n",
        "\n",
        "df.drop('Date', axis=1, inplace = True)\n",
        ""
      ],
      "metadata": {
        "id": "Q3yk7Dg1tUtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "# One Hot **Encoding**"
      ],
      "metadata": {
        "id": "0aQSVUHltg4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's do One Hot Encoding of Location variable\n",
        "# get k-1 dummy variables after One Hot Encoding\n",
        "# preview the dataset with head() method\n",
        "\n",
        "pd.get_dummies(df.Location, drop_first=True).head()\n",
        "\n",
        "\"\"\"\n",
        "The code `pd.get_dummies(df.Location, drop_first=True).head()` is used to perform one-hot encoding on the\n",
        "categorical variable \"Location\" in the DataFrame `df`.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "1. `pd.get_dummies(df.Location, drop_first=True)`:\n",
        "   - `pd.get_dummies()` is a pandas function that converts categorical variables into dummy/indicator variables.\n",
        "   - `df.Location` selects the \"Location\" column from the DataFrame `df` to be one-hot encoded.\n",
        "   - `drop_first=True` is an optional parameter that specifies whether to drop the first category\n",
        "      in each variable. This is done to prevent multicollinearity issues when using\n",
        "      the one-hot encoded variables in a regression model.\n",
        "\n",
        "2. `.head()`:\n",
        "   - The `.head()` method is called on the resulting DataFrame to display the first few rows.\n",
        "\n",
        "The output of this code will be a DataFrame that contains the one-hot encoded representation\n",
        "of the \"Location\" variable, where each unique category in the \"Location\" column is\n",
        "represented by a separate binary column. The `drop_first=True` parameter ensures that\n",
        "only (n-1) dummy columns are created for n categories."
      ],
      "metadata": {
        "id": "-3T8fSDhtgWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sum the number of 1s per boolean variable over the rows of the dataset\n",
        "# it will tell us how many observations we have for each category\n",
        "\n",
        "pd.get_dummies(df.WindGustDir, drop_first=True, dummy_na=True).sum(axis=0)\n",
        "\n",
        "\n",
        "'''\n",
        "axis=0 specifies that the sum should be calculated vertically, i.e., for each category column.\n",
        "The output of this code will be a Series that shows the sum of the number of occurrences (1s)\n",
        "per category in the \"WindGustDir\" column. Each category will be represented as an index label in the Series,\n",
        "and the corresponding value will be the sum of occurrences for that category.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "zDY2v9rAuv3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Explore Numerical Variables**"
      ],
      "metadata": {
        "id": "qBghsmDQwCwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find numerical variables\n",
        "\n",
        "numerical = [var for var in df.columns if df[var].dtype!='O']\n",
        "\n",
        "print('There are {} numerical variables\\n'.format(len(numerical)))\n",
        "\n",
        "print('The numerical variables are :', numerical)\n",
        "\n",
        "\n",
        "\n",
        "output:-There are 19 numerical variables\n",
        "'''\n",
        "The code snippet is used to find and display the numerical variables in a DataFrame `df`.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "1. `numerical = [var for var in df.columns if df[var].dtype!='O']`:\n",
        "   - This line creates a list comprehension that iterates over the columns of the DataFrame `df`.\n",
        "   - For each column, it checks if the data type is not equal to `'O'`,\n",
        "    indicating that it is not an object or string type column (numerical variable).\n",
        "   - If the condition is met, the column name is added to the `numerical` list.\n",
        "\n",
        "2. `print('There are {} numerical variables\\n'.format(len(numerical)))`:\n",
        "   - This line prints the number of numerical variables found in the DataFrame using string formatting.\n",
        "   - The `len(numerical)` returns the length (number of elements) of the `numerical` list.\n",
        "   - The number is inserted into the string using `{}` as a placeholder, and `.format()`\n",
        "    is used to substitute the value into the string.\n",
        "\n",
        "3. `print('The numerical variables are :', numerical)`:\n",
        "   - This line prints the list of numerical variables found in the DataFrame.\n",
        "   - The list `numerical` is printed as is, displaying the names of the numerical variables.\n",
        "\n",
        "The output of this code will be the number of numerical variables found in the DataFrame `df` and the list of their names.\n",
        "'''\n",
        ""
      ],
      "metadata": {
        "id": "z1iuDW2yv0Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view summary statistics in numerical variables\n",
        "\n",
        "print(round(df[numerical].describe()),2)\n",
        "\n",
        "\n",
        "'''\n",
        "The code `print(round(df[numerical].describe()),2)` is used to view summary\n",
        "statistics of the numerical variables in the DataFrame `df`.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "1. `df[numerical].describe()`:\n",
        "   - This line selects the columns corresponding to the numerical variables in\n",
        "   the DataFrame `df` using `df[numerical]`.\n",
        "   - `.describe()` is a method that computes various summary statistics of the\n",
        "   selected numerical columns, including count, mean, standard deviation, minimum value,\n",
        "    25th percentile, median (50th percentile), 75th percentile, and maximum value.\n",
        "\n",
        "2. `round(..., 2)`:\n",
        "   - The `round()` function is used to round the values in the summary statistics to two decimal places.\n",
        "   - It takes the result of `df[numerical].describe()` as input and specifies the number of decimal places to round to.\n",
        "\n",
        "3. `print(...)`:\n",
        "   - This line prints the rounded summary statistics of the numerical variables.\n",
        "\n",
        "The output of this code will be the summary statistics of the numerical variables in\n",
        " the DataFrame `df`, including count, mean, standard deviation, minimum value, quartiles,\n",
        "  and maximum value, rounded to two decimal places.\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "XLmDThuJwRzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "fig = df.boxplot(column='Rainfall')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('Rainfall')\n",
        "\n",
        "'''\n",
        "The code snippet is used to create a boxplot of the \"Rainfall\" variable in the DataFrame `df` using Matplotlib.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "1. `plt.figure(figsize=(15,10))`:\n",
        "   - This line creates a new figure with a specified figure size of 15 inches (width) and 10 inches (height).\n",
        "   - The `figsize` parameter is set using a tuple `(15, 10)`.\n",
        "\n",
        "2. `plt.subplot(2, 2, 1)`:\n",
        "   - This line creates a subplot in a 2x2 grid and selects the first subplot (top-left).\n",
        "   - The `subplot` function takes three arguments: the number of rows, the number of columns,\n",
        "     and the index of the subplot to select.\n",
        "   - In this case, a 2x2 grid is created, and the first subplot is selected with an index of 1.\n",
        "\n",
        "3. `fig = df.boxplot(column='Rainfall')`:\n",
        "   - This line creates a boxplot of the \"Rainfall\" variable in the DataFrame `df`.\n",
        "   - The `column` parameter is set to `'Rainfall'` to specify the column to use for the boxplot.\n",
        "   - The resulting boxplot is assigned to the variable `fig`.\n",
        "\n",
        "4. `fig.set_title('')`:\n",
        "   - This line sets an empty title for the boxplot.\n",
        "   - The `set_title()` method is called on the `fig` object.\n",
        "\n",
        "5. `fig.set_ylabel('Rainfall')`:\n",
        "   - This line sets the label for the y-axis of the boxplot to `'Rainfall'`.\n",
        "   - The `set_ylabel()` method is called on the `fig` object.\n",
        "\n",
        "     The output of this code will be a boxplot of the \"Rainfall\" variable in the DataFrame `df`,\n",
        "     displayed in the first subplot of a 2x2 grid. The y-axis will be labeled as \"Rainfall\".\n",
        "'''"
      ],
      "metadata": {
        "id": "PdPtWNbBxY9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "fig = df.Rainfall.hist(bins=10)\n",
        "fig.set_xlabel('Rainfall')\n",
        "fig.set_ylabel('RainTomorrow')\n"
      ],
      "metadata": {
        "id": "eAGj8k1UyByV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find outliers for Rainfall variable\n",
        "\n",
        "IQR = df.Rainfall.quantile(0.75) - df.Rainfall.quantile(0.25)\n",
        "Lower_fence = df.Rainfall.quantile(0.25) - (IQR * 3)\n",
        "Upper_fence = df.Rainfall.quantile(0.75) + (IQR * 3)\n",
        "print('Rainfall outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))\n",
        "\n",
        "Rainfall outliers are values < -2.4000000000000004 or > 3.2\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "The code snippet is used to find outliers for the \"Rainfall\" variable in the DataFrame `df`.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "1. `IQR = df.Rainfall.quantile(0.75) - df.Rainfall.quantile(0.25)`:\n",
        "   - This line calculates the interquartile range (IQR) of the \"Rainfall\" variable.\n",
        "   - The `.quantile()` method is used to calculate the 25th percentile (Q1) and\n",
        "   the 75th percentile (Q3), and the difference between them gives the IQR.\n",
        "\n",
        "2. `Lower_fence = df.Rainfall.quantile(0.25) - (IQR * 3)`:\n",
        "   - This line calculates the lower fence for outliers.\n",
        "   - The lower fence is calculated as Q1 - (IQR * 3), where Q1 is the 25th percentile.\n",
        "\n",
        "3. `Upper_fence = df.Rainfall.quantile(0.75) + (IQR * 3)`:\n",
        "   - This line calculates the upper fence for outliers.\n",
        "   - The upper fence is calculated as Q3 + (IQR * 3), where Q3 is the 75th percentile.\n",
        "\n",
        "4. `print('Rainfall outliers are values < {lowerboundary} or > {upperboundary}'\n",
        "    .format(lowerboundary=Lower_fence, upperboundary=Upper_fence))`:\n",
        "   -This line prints the range of values that are considered outliers for the \"Rainfall\" variable.\n",
        "   -The format string `{lowerboundary}` and `{upperboundary}` are replaced with the values of\n",
        "    Lower_fence` and `Upper_fence`, respectively.\n",
        "   -This provides the lower and upper boundaries for outliers based on the calculated fences.\n",
        "\n",
        "The output of this code will be a message indicating the range of values that are considered outliers\n",
        "for the \"Rainfall\" variable. In this case, it states that outliers are values less than -2.4 or greater than 3.2."
      ],
      "metadata": {
        "id": "hKgP3gMJyDtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**drop target column**"
      ],
      "metadata": {
        "id": "nabfUW1rzRJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['RainTomorrow'], axis=1)\n",
        "\n",
        "y = df['RainTomorrow']\n",
        "\n",
        "'''\n",
        "After executing this code, X will contain the independent variable(s) (all columns except 'RainTomorrow')\n",
        "and y will contain the dependent variable ('RainTomorrow').\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "-pi6Ho6Ay1k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**percentage of missing values in the numerical variables in training set**"
      ],
      "metadata": {
        "id": "GHfvbdxPzIHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print percentage of missing values in the numerical variables in training set\n",
        "\n",
        "for col in numerical:\n",
        "    if X_train[col].isnull().mean()>0:\n",
        "        print(col, round(X_train[col].isnull().mean(),4))\n",
        "     '''\n",
        "     The code is used to identify numerical variables in the `X_train` DataFrame that have missing values\n",
        "      and print the variable names along with the proportion of missing values.\n",
        "\n",
        "Here's how it works:\n",
        "\n",
        "1. `for col in numerical:`: This line iterates over each variable name in the `numerical` list,\n",
        "    which contains the names of the numerical variables in the `X_train` DataFrame.\n",
        "\n",
        "2. `if X_train[col].isnull().mean()>0:`: This line checks if the selected variable (`col`)\n",
        "    in the `X_train` DataFrame\n",
        "    has missing values. It does this by calculating the mean of the boolean mask `X_train[col].isnull()`,\n",
        "    which indicates whether each value in the variable is missing or not. If the mean is greater than 0,\n",
        "    it means there are missing values in that variable.\n",
        "\n",
        "3. `print(col, round(X_train[col].isnull().mean(),4))`: If there are missing values in the variable,\n",
        "    this line prints the variable name (`col`) and the proportion of missing values for that variable.\n",
        "    The `round()` function is used to round the proportion to four decimal places.\n",
        "\n",
        "By running this code, you will get a list of numerical variables in the `X_train` DataFrame that have missing values,\n",
        "along with the proportion of missing values for each variable."
      ],
      "metadata": {
        "id": "FizfnUgAzEnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# impute missing values in X_train and X_test with respective column median in X_train\n",
        "\n",
        "for df1 in [X_train, X_test]:\n",
        "    for col in numerical:\n",
        "        col_median=X_train[col].median()\n",
        "        df1[col].fillna(col_median, inplace=True)\n",
        "\n",
        "'''\n",
        "The code snippet is used to impute missing values in the `X_train` and `X_test` DataFrames\n",
        "using the respective column medians from the `X_train` DataFrame.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "1. `for df1 in [X_train, X_test]:`:\n",
        "   - This line iterates over the list `[X_train, X_test]`, which contains the `X_train` and `X_test` DataFrames.\n",
        "\n",
        "2. `for col in numerical:`:\n",
        "   - This line iterates over each variable name in the `numerical` list, which\n",
        "     contains the names of the numerical variables.\n",
        "\n",
        "3. `col_median = X_train[col].median()`:\n",
        "   - This line calculates the median of the selected variable (`col`) in the `X_train` DataFrame.\n",
        "   - The `.median()` method is used to calculate the median value.\n",
        "\n",
        "4. `df1[col].fillna(col_median, inplace=True)`:\n",
        "   - This line fills the missing values in the selected variable (`col`) of the current DataFrame (`df1`)\n",
        "     with the corresponding column median from the `X_train` DataFrame.\n",
        "   - The `.fillna()` method is used to fill missing values, and `col_median` is used as the value\n",
        "     to fill the missing values with.\n",
        "   - The `inplace=True` argument ensures that the changes are applied directly to the DataFrame.\n",
        "\n",
        "By executing this code, the missing values in the numerical variables of both `X_train` and `X_test`\n",
        "will be imputed with the respective column medians from the `X_train` DataFrame.\n",
        "'''"
      ],
      "metadata": {
        "id": "uHv572Dx0_BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Engineering missing values in categorical variables¶**"
      ],
      "metadata": {
        "id": "LXn04P962HL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print percentage of missing values in the categorical variables in training set\n",
        "\n",
        "X_train[categorical].isnull().mean()\n",
        "\n",
        "Location       0.000000\n",
        "WindGustDir    0.065114\n",
        "\n",
        "dtype: float64\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print categorical variables with missing data\n",
        "\n",
        "for col in categorical:\n",
        "    if X_train[col].isnull().mean()>0:\n",
        "        print(col, (X_train[col].isnull().mean()))\n",
        "\n",
        "WindGustDir 0.06511419378659213\n",
        "WindDir9am 0.07013379749283542\n",
        "\n",
        "\n",
        "# impute missing categorical variables with most frequent value\n",
        "\n",
        "for df2 in [X_train, X_test]:\n",
        "    df2['WindGustDir'].fillna(X_train['WindGustDir'].mode()[0], inplace=True)\n",
        "    df2['WindDir9am'].fillna(X_train['WindDir9am'].mode()[0], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# check missing values in categorical variables in X_test\n",
        "\n",
        "X_test[categorical].isnull().sum()\n",
        "\n",
        "\n",
        "\n",
        "# As a final check, we will check for missing values in X_train and X_test.\n",
        "\n",
        "# check missing values in X_train\n",
        "\n",
        "X_train.isnull().sum()\n",
        "\n"
      ],
      "metadata": {
        "id": "Xm2IB1Dd2LyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Engineering outliers in numerical variables**\n"
      ],
      "metadata": {
        "id": "aIAqSrW_3Ffu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def max_value(df3, variable, top):\n",
        "    return np.where(df3[variable]>top, top, df3[variable])\n",
        "\n",
        "for df3 in [X_train, X_test]:\n",
        "    df3['Rainfall'] = max_value(df3, 'Rainfall', 3.2)\n",
        "    df3['Evaporation'] = max_value(df3, 'Evaporation', 21.8)\n",
        "\n",
        "'''\n",
        "The code snippet defines a function `max_value` and uses it to cap the values in the\n",
        "'Rainfall' and 'Evaporation' variables in both the `X_train` and `X_test` DataFrames.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "1. `def max_value(df3, variable, top):`:\n",
        "   - This line defines a function named `max_value` that takes three arguments: `df3` (DataFrame),\n",
        "   `variable` (name of the variable), and `top` (maximum value to cap).\n",
        "\n",
        "2. `return np.where(df3[variable]>top, top, df3[variable])`:\n",
        "   - This line uses `np.where` to compare the values in the specified variable (`variable`)\n",
        "     of the DataFrame (`df3`) with the given `top` value.\n",
        "   - If a value in the variable is greater than `top`, it is replaced with `top`; otherwise,\n",
        "     the original value is kept.\n",
        "   - The function returns the resulting array of capped values.\n",
        "\n",
        "3. `for df3 in [X_train, X_test]:`:\n",
        "   - This line iterates over the list `[X_train, X_test]`, which contains\n",
        "     the `X_train` and `X_test` DataFrames.\n",
        "\n",
        "4. `df3['Rainfall'] = max_value(df3, 'Rainfall', 3.2)`:\n",
        "   - This line calls the `max_value` function to cap the values in the 'Rainfall' variable\n",
        "     of the current DataFrame (`df3`) at 3.2.\n",
        "   - The capped values are assigned back to the 'Rainfall' variable in the DataFrame.\n",
        "\n",
        "5. `df3['Evaporation'] = max_value(df3, 'Evaporation', 21.8)`:\n",
        "   - This line calls the `max_value` function to cap the values in the 'Evaporation'\n",
        "     variable of the current DataFrame (`df3`) at 21.8.\n",
        "   - The capped values are assigned back to the 'Evaporation' variable in the DataFrame.\n",
        "\n",
        "By executing this code, the values in the 'Rainfall' and 'Evaporation' variables of\n",
        "both `X_train` and `X_test` will be capped at the specified maximum values.\n",
        "Any value greater than the maximum will be replaced with the maximum value."
      ],
      "metadata": {
        "id": "5rqq97uR3Eyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install category-encoders\n",
        "\n",
        "# encode RainToday variable\n",
        "\n",
        "import category_encoders as ce\n",
        "\n",
        "encoder = ce.BinaryEncoder(cols=['RainToday'])\n",
        "\n",
        "X_train = encoder.fit_transform(X_train)\n",
        "\n",
        "X_test = encoder.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "The code snippet is used to encode the 'RainToday' variable using binary encoding.\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "1. `import category_encoders as ce`:\n",
        "   - This line imports the `category_encoders` library, which provides various\n",
        "     encoding techniques for categorical variables.\n",
        "\n",
        "2. `encoder = ce.BinaryEncoder(cols=['RainToday'])`:\n",
        "   - This line creates an instance of the `BinaryEncoder` class from `category_encoders`.\n",
        "   - The `BinaryEncoder` is a type of categorical encoding that converts categorical\n",
        "     variables into binary representations.\n",
        "\n",
        "3. `X_train = encoder.fit_transform(X_train)`:\n",
        "   - This line applies the binary encoding transformation to\n",
        "     the 'RainToday' variable in the `X_train` DataFrame.\n",
        "   - The `.fit_transform()` method is used to fit the encoder on the training data (`X_train`) and\n",
        "     transform it into the encoded representation.\n",
        "   - The transformed data is assigned back to the `X_train` DataFrame, overwriting\n",
        "     the original 'RainToday' variable with the encoded binary columns.\n",
        "\n",
        "4. `X_test = encoder.transform(X_test)`:\n",
        "   - This line applies the same binary encoding transformation\n",
        "     to the 'RainToday' variable in the `X_test` DataFrame.\n",
        "   - The `.transform()` method is used to transform the test data (`X_test`) using the fitted encoder.\n",
        "   - The transformed data is assigned back to the `X_test` DataFrame, replacing\n",
        "     the original 'RainToday' variable with the encoded binary columns.\n",
        "\n",
        "By executing this code, the 'RainToday' variable in both `X_train` and `X_test` will be\n",
        "encoded using binary encoding. Each category in the variable will be represented by a set of binary columns,\n",
        " with each column indicating the presence or absence of a particular category.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "qQEU6eSv4jiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "'''\n",
        "The code snippet is used to apply min-max scaling to the features in\n",
        "the `X_train` and `X_test` datasets. Here's a breakdown of the code:\n",
        "\n",
        "1. `from sklearn.preprocessing import MinMaxScaler`:\n",
        "   - This line imports the `MinMaxScaler` class from the `sklearn.preprocessing` module,\n",
        "     which is used for min-max scaling.\n",
        "\n",
        "2. `scaler = MinMaxScaler()`:\n",
        "   - This line creates an instance of the `MinMaxScaler` class,\n",
        "     which will be used to perform the scaling.\n",
        "\n",
        "3. `X_train = scaler.fit_transform(X_train)`:\n",
        "   - This line applies the min-max scaling transformation to the features in the `X_train` dataset.\n",
        "   - The `.fit_transform()` method is used to fit the scaler on\n",
        "     the training data (`X_train`) and transform it.\n",
        "   - The transformed data is assigned back to the `X_train` dataset,\n",
        "     overwriting the original feature values with the scaled values.\n",
        "\n",
        "4. `X_test = scaler.transform(X_test)`:\n",
        "   - This line applies the same scaling transformation to the features in the `X_test` dataset.\n",
        "   - The `.transform()` method is used to transform the test data (`X_test`) using the fitted scaler.\n",
        "   - The transformed data is assigned back to the `X_test` dataset,\n",
        "     replacing the original feature values with the scaled values.\n",
        "\n",
        "By executing this code, the features in both `X_train` and `X_test` will be scaled\n",
        " using min-max scaling. Min-max scaling transforms the values of each feature to a range between 0 and 1, based\n",
        " on the minimum and maximum values of the feature in the training data. This scaling ensures\n",
        " that all features have a similar scale and prevents any particular feature\n",
        " from dominating the learning algorithm based on its magnitude.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "aud5-Kdt5hUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# probability of getting output as 0 - no rain\n",
        "\n",
        "logreg.predict_proba(X_test)[:,0]\n",
        "\n",
        "\n",
        "# probability of getting output as 1 - rain\n",
        "\n",
        "logreg.predict_proba(X_test)[:,1]\n",
        "\n",
        "\n",
        "#from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\n",
        "\n",
        "Model accuracy score: 0.8502\n"
      ],
      "metadata": {
        "id": "g5AWGRi56d8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Compare the train-set and test-set accuracy**"
      ],
      "metadata": {
        "id": "Tggwyp7H6_Cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = logreg.predict(X_train)\n",
        "\n",
        "y_pred_train\n",
        "\n",
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))\n",
        "\n",
        "Training-set accuracy score: 0.8476"
      ],
      "metadata": {
        "id": "u0dxL4ke65PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check for overfitting and underfitting**"
      ],
      "metadata": {
        "id": "H7vzZ-T-7Nhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print the scores on training and test set\n",
        "\n",
        "print('Training set score: {:.4f}'.format(logreg.score(X_train, y_train)))\n",
        "\n",
        "print('Test set score: {:.4f}'.format(logreg.score(X_test, y_test)))\n",
        "\n",
        "Training set score: 0.8476\n",
        "Test set score: 0.8502\n"
      ],
      "metadata": {
        "id": "DWiBXpUL7GRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the Confusion Matrix and slice it into four pieces\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
        "\n",
        "Confusion matrix\n",
        "\n",
        " [[20892  1175]\n",
        " [ 3086  3286]]\n",
        "\n",
        "True Positives(TP) =  20892\n",
        "\n",
        "True Negatives(TN) =  3286\n",
        "\n",
        "False Positives(FP) =  1175\n",
        "\n",
        "False Negatives(FN) =  3086\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The confusion matrix shows 20892 + 3285 = 24177 correct predictions and\n",
        " 3087 + 1175 = 4262 incorrect predictions.\n",
        "\n",
        "In this case, we have\n",
        "\n",
        "True Positives (Actual Positive:1 and Predict Positive:1) - 20892\n",
        "\n",
        "True Negatives (Actual Negative:0 and Predict Negative:0) - 3285\n",
        "\n",
        "False Positives (Actual Negative:0 but Predict Positive:1) - 1175 (Type I error)\n",
        "\n",
        "False Negatives (Actual Positive:1 but Predict Negative:0) - 3087 (Type II error)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "A confusion matrix is a table that is used to evaluate the performance of a classification model.\n",
        "It summarizes the predictions made by the model on a test dataset and compares them to the actual class labels.\n",
        "The confusion matrix provides insights into the accuracy of the model by breaking\n",
        "down the predictions into four categories: true positives (TP), true negatives (TN),\n",
        " false positives (FP), and false negatives (FN).\n",
        "\n",
        "Here's a breakdown of the code and the information provided by the confusion matrix:\n",
        "\n",
        "1. `from sklearn.metrics import confusion_matrix`:\n",
        "   - This line imports the `confusion_matrix` function from the `sklearn.metrics` module,\n",
        "     which is used to compute the confusion matrix.\n",
        "\n",
        "2. `cm = confusion_matrix(y_test, y_pred_test)`:\n",
        "   - This line calculates the confusion matrix by comparing the true class\n",
        "     labels (`y_test`) with the predicted class labels (`y_pred_test`).\n",
        "\n",
        "3. `print('Confusion matrix\\n\\n', cm)`:\n",
        "   - This line prints the confusion matrix, which is a table showing the counts\n",
        "     of true positives, true negatives, false positives, and false negatives.\n",
        "\n",
        "4. `print('\\nTrue Positives(TP) = ', cm[0,0])`:\n",
        "   - This line prints the count of true positives (TP), which represents the number\n",
        "      of observations that were correctly predicted as positive.\n",
        "\n",
        "5. `print('\\nTrue Negatives(TN) = ', cm[1,1])`:\n",
        "   - This line prints the count of true negatives (TN), which represents the number\n",
        "     of observations that were correctly predicted as negative.\n",
        "\n",
        "6. `print('\\nFalse Positives(FP) = ', cm[0,1])`:\n",
        "   - This line prints the count of false positives (FP), which represents the number\n",
        "     of observations that were incorrectly predicted as positive.\n",
        "\n",
        "7. `print('\\nFalse Negatives(FN) = ', cm[1,0])`:\n",
        "   - This line prints the count of false negatives (FN), which represents the number\n",
        "     of observations that were incorrectly predicted as negative.\n",
        "\n",
        "Summary:\n",
        "The confusion matrix provided by the code has the following information:\n",
        "- True Positives (TP): 20,892\n",
        "- True Negatives (TN): 3,286\n",
        "- False Positives (FP): 1,175\n",
        "- False Negatives (FN): 3,086\n",
        "\n",
        "The confusion matrix allows us to assess the performance of a classification model by providing a\n",
        "comprehensive view of its predictive accuracy. The counts in each category help us understand how well\n",
        "the model is correctly classifying positive and negative instances.\n"
      ],
      "metadata": {
        "id": "liMCOtYh7igt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize confusion matrix with seaborn heatmap\n",
        "\n",
        "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],\n",
        "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "The code you provided visualizes the confusion matrix using a heatmap\n",
        "with the help of the Seaborn library.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "1. `cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],\n",
        "     index=['Predict Positive:1', 'Predict Negative:0'])`:\n",
        "   - This line creates a Pandas DataFrame called `cm_matrix` using the values\n",
        "     from the confusion matrix `cm`.\n",
        "   - It specifies the column names as \"Actual Positive:1\" and \"Actual Negative:0\"\n",
        "     to represent the actual class labels.\n",
        "   - It also specifies the index names as \"Predict Positive:1\" and \"Predict Negative:0\"\n",
        "     to represent the predicted class labels.\n",
        "\n",
        "2. `sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')`:\n",
        "   - This line uses the Seaborn `heatmap` function to create a heatmap of the `cm_matrix` DataFrame.\n",
        "   - The `annot=True` parameter adds the values from the confusion matrix to each cell of the heatmap.\n",
        "   - The `fmt='d'` parameter specifies that the values should be displayed as integers.\n",
        "   - The `cmap='YlGnBu'` parameter sets the color scheme of the heatmap.\n",
        "\n",
        " The resulting heatmap visualizes the confusion matrix, where the rows represent the predicted\n",
        " class labels and the columns represent the actual class labels. The color intensity of each cell\n",
        " indicates the count of observations falling into that category. The annotated values inside the cells\n",
        " provide additional information about the counts.\n",
        "\n",
        "By visualizing the confusion matrix, you can get a clearer understanding of the distribution\n",
        "of predictions and evaluate the performance of the classification model.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "h4UVzktA8GRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          No       0.87      0.95      0.91     22067\n",
        "         Yes       0.74      0.52      0.61      6372\n",
        "\n",
        "    accuracy                           0.85     28439\n",
        "   macro avg       0.80      0.73      0.76     28439\n",
        "weighted avg       0.84      0.85      0.84     28439\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "The classification report provides various performance metrics for each class in a classification problem.\n",
        " Here's an explanation of the metrics in the classification report and their interpretation:\n",
        "\n",
        "- Precision: Precision measures the accuracy of positive predictions. It is calculated as\n",
        "   the ratio of true positive predictions\n",
        "   to the total predicted positives. In the classification report, precision is reported for each class.\n",
        "   In this case, the precision for the \"No\" class is 0.87, and for the \"Yes\" class is 0.74. Higher precision\n",
        "   values indicate a lower rate of false positive predictions.\n",
        "\n",
        "- Recall: Recall, also known as sensitivity or true positive rate, measures the proportion of actual positives\n",
        " that are correctly identified. It is calculated as the ratio of true positive predictions to\n",
        " the total actual positives.In the classification report, recall is reported for each class. In this case,\n",
        " the recall for the \"No\" class is 0.95, andfor the \"Yes\" class is 0.52. Higher recall values indicate\n",
        " a lower rate of false negative predictions.\n",
        "\n",
        "- F1-score: The F1-score is the harmonic mean of precision and recall. It provides a balanced measure of\n",
        " the model's accuracy by considering both precision and recall. The F1-score is reported for each class\n",
        " in the classification report. In this case, the F1-score for the \"No\" class is 0.91, and for the \"Yes\" class is 0.61.\n",
        "  The F1-score ranges from 0 to 1, with a higher value indicating better performance.\n",
        "\n",
        "- Support: Support refers to the number of samples in each class. It provides an indication of\n",
        "the imbalance in the dataset.\n",
        "In the classification report, support is reported for each class. In this case, there are 22,067 samples in\n",
        "the \"No\" class and 6,372 samples in the \"Yes\" class.\n",
        "\n",
        "- Accuracy: Accuracy measures the overall correctness of the model's predictions.\n",
        "It is calculated as the ratio of correct predictions to the total number of predictions.\n",
        "In this case, the accuracy is reported as 0.85, indicating that the model predicts\n",
        " the correct class for 85% of the samples.\n",
        "\n",
        "- Macro Avg: The macro average calculates the average metric across all classes,\n",
        "giving equal weight to each class. In the classification report, the macro average precision, recall,\n",
        "and F1-score are reported. In this case, the macro average precision is 0.80,\n",
        "the recall is 0.73, and the F1-score is 0.76.\n",
        "\n",
        "- Weighted Avg: The weighted average calculates the average metric across all classes,\n",
        " weighted by the number of samples in each class. In the classification report,\n",
        " the weighted average precision, recall, and F1-score are reported. In this case,\n",
        " the weighted average precision is 0.84, the recall is 0.85, and the F1-score is 0.84.\n",
        "\n",
        "In general, higher precision, recall, and F1-score values indicate better model performance.\n",
        " However, the interpretation of what is considered a good or bad score depends on the specific context\n",
        " and requirements of the classification problem. It is important to consider the trade-off between precision\n",
        " and recall based on the specific needs of the application.\n",
        "'''"
      ],
      "metadata": {
        "id": "GA6LcrfV91W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP = cm[0,0]\n",
        "TN = cm[1,1]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]\n",
        "\n",
        "\n",
        "# print classification accuracy\n",
        "\n",
        "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))\n",
        "\n",
        "Classification accuracy : 0.8502\n",
        "\n",
        "\n",
        "\n",
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification error : {0:0.4f}'.format(classification_error))\n",
        "\n",
        "Classification error : 0.1498\n",
        "\n",
        "\n",
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification error : {0:0.4f}'.format(classification_error))\n",
        "\n",
        "Classification error : 0.1498\n",
        "\n",
        "\n",
        "# recall score\n",
        "\n",
        "recall = TP / float(TP + FN)\n",
        "\n",
        "print('Recall or Sensitivity : {0:0.4f}'.format(recall))\n",
        "\n",
        "Recall or Sensitivity : 0.8713\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#True Positive Rate\n",
        "#True Positive Rate is synonymous with Recall.\n",
        "\n",
        "true_positive_rate = TP / float(TP + FN)\n",
        "\n",
        "print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))\n",
        "\n",
        "True Positive Rate : 0.8713\n",
        "\n",
        "\n",
        "#False Positive Rate\n",
        "\n",
        "false_positive_rate = FP / float(FP + TN)\n",
        "\n",
        "\n",
        "print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))\n",
        "\n",
        "False Positive Rate : 0.2634\n",
        "\n",
        "\n",
        "# Specificity\n",
        "\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print('Specificity : {0:0.4f}'.format(specificity))\n",
        "\n",
        "Specificity : 0.7366\n",
        "\n"
      ],
      "metadata": {
        "id": "Oww-aqZx_CPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusting the threshold level\n",
        "\n",
        "# print the first 10 predicted probabilities of two classes- 0 and 1\n",
        "\n",
        "y_pred_prob = logreg.predict_proba(X_test)[0:10]\n",
        "\n",
        "y_pred_prob\n",
        "\n",
        "array([[0.91382428, 0.08617572],\n",
        "       [0.83565645, 0.16434355]])\n",
        "'''\n",
        "The code snippet is calculating and printing the predicted probabilities for the first 10 samples\n",
        " in the test set using the logistic regression model (logreg). The predicted probabilities represent the model's\n",
        " estimated probability for each sample belonging to each class (0 and 1).\n",
        "\n",
        "The output shows an array of shape (10, 2), where each row represents the predicted probabilities for a sample.\n",
        " The first column represents the probability of belonging to class 0, and\n",
        " the second column represents the probability of belonging to class 1.\n",
        "\n",
        "For example, the first row [0.91382428, 0.08617572] indicates that the model predicts\n",
        "a high probability (0.91382428) for the sample to belong to class 0 and a low probability (0.08617572)\n",
        "for it to belong to class 1. Similarly, the second row [0.83565645, 0.16434355] shows\n",
        "the predicted probabilities for another sample.\n",
        "'''"
      ],
      "metadata": {
        "id": "bY74tquRAHgQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}