{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOa0DsjgoMCwx/8NkV5ht1H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amarsinh0/MY-NOTES/blob/main/ml_code_collection%20_2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9h7rLdFIpa8",
        "outputId": "65b63256-930a-4073-8a8e-9ee4ac4c0db4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n"
          ]
        }
      ],
      "source": [
        "print(\"hello world\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas  as pd #Data manipulation\n",
        "import numpy as np #Data manipulation\n",
        "import matplotlib.pyplot as plt # Visualization\n",
        "import seaborn as sns #Visualization\n",
        "plt.rcParams['figure.figsize'] = [8,5]\n",
        "plt.rcParams['font.size'] =14\n",
        "plt.rcParams['font.weight']= 'bold'\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "\"\"\"\n",
        "plt.rcParams['figure.figsize'] = [8,5]\n",
        "\n",
        "This line sets the default figure size for plots created with matplotlib and seaborn.\n",
        "It specifies the width and height of the figure in inches.\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "This line sets the default font size for text elements in plots created with matplotlib and seaborn.\n",
        " It specifies the font size in points.\n",
        "plt.rcParams['font.weight'] = 'bold'\n",
        "\n",
        "This line sets the default font weight for text elements in plots created with matplotlib and seaborn.\n",
        "It specifies that the font weight should be bold.\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "This line sets the default style for plots created with matplotlib and seaborn.\n",
        "It uses the 'seaborn-whitegrid' style, which provides a white background with gridlines for better visibility of the plotted data points.\n",
        "These configurations ensure consistent and visually appealing plots throughout the code\n",
        " by setting default values for figure size, font size, font weight, and style.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "a2pTgrLgIyPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" for our visualization purpose will fit line using seaborn library only for bmi as independent variable\n",
        "and charges as dependent variable\"\"\"\n",
        "\n",
        "sns.lmplot(x='bmi',y='charges',data=df,aspect=2,height=6)\n",
        "plt.xlabel('Boby Mass Index(kg/m2): as Independent variable')\n",
        "plt.ylabel('Insurance Charges: as Dependent variable')\n",
        "plt.title('Charge Vs BMI');\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  The code you provided uses the seaborn library to fit a linear regression line between the 'bmi' variable\n",
        "   (independent variable) and the 'charges' variable (dependent variable). Here's a breakdown of each line:\n",
        "\n",
        "- `sns.lmplot(x='bmi', y='charges', data=df, aspect=2, height=6)`\n",
        "   - This line creates a scatter plot with a linear regression line using the lmplot function from seaborn.\n",
        "   It specifies 'bmi' as the x-axis variable, 'charges' as the y-axis variable, and uses the data stored in the 'df' DataFrame.\n",
        "   The aspect ratio is set to 2 and the height of the plot is set to 6 inches.\n",
        "\n",
        "- `plt.xlabel('Body Mass Index: as Independent variable')`\n",
        "   - This line sets the label for the x-axis as 'Body Mass Index: as Independent variable'\n",
        "   using the xlabel function from matplotlib.pyplot. It provides a descriptive label for the independent variable.\n",
        "\n",
        "- `plt.ylabel('Insurance Charges: as Dependent variable')`\n",
        "   - This line sets the label for the y-axis as 'Insurance Charges: as Dependent variable'\n",
        "   using the ylabel function from matplotlib.pyplot. It provides a descriptive label for the dependent variable.\n",
        "\n",
        "- `plt.title('Charge Vs BMI')`\n",
        "   - This line sets the title of the plot as 'Charge Vs BMI' using the title function from matplotlib.pyplot.\n",
        "    It provides a descriptive title for the plot.\n",
        "\n",
        "Overall, this code generates a scatter plot with a linear regression line, where the x-axis represents the 'bmi' variable\n",
        "(independent variable) and the y-axis represents the 'charges' variable (dependent variable).\n",
        " The plot allows you to visualize the relationship between BMI and insurance charges and to observe the trend indicated by\n",
        " the linear regression line. The labels and title provide additional information and context for the plot.\n",
        "\n",
        "  \"\"\"\""
      ],
      "metadata": {
        "id": "U7m-4TeuJRzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory data analysis**"
      ],
      "metadata": {
        "id": "pFPxkbceKI3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Check for missing valueÂ¶\n",
        "#There is no missing value in the data sex\n",
        "plt.figure(figsize=(12,4))\n",
        "sns.heatmap(df.isnull(),cbar=False,cmap='viridis',yticklabels=False)\n",
        "plt.title('Missing value in the dataset');\n",
        "\n",
        "\"\"\"\n",
        "The code you provided checks for missing values in the 'df' DataFrame and creates a heatmap visualization.\n",
        " Here's a breakdown of each line:\n",
        "\n",
        "- `plt.figure(figsize=(12,4))`\n",
        "   - This line sets the figure size to (12,4) inches using the figure function from matplotlib.pyplot.\n",
        "    It specifies the dimensions of the figure that will contain the heatmap.\n",
        "\n",
        "- `sns.heatmap(df.isnull(), cbar=False, cmap='viridis', yticklabels=False)`\n",
        "   - This line creates a heatmap using the heatmap function from seaborn. It takes the 'df.isnull()'\n",
        "    DataFrame as input, which returns a boolean DataFrame with True values where missing values are present.\n",
        "     The heatmap visualizes this boolean DataFrame, where missing values are represented as True (colored cells)\n",
        "     and non-missing values are represented as False (blank cells).\n",
        "   - `cbar=False` removes the color bar from the heatmap.\n",
        "   - `cmap='viridis'` sets the color map to 'viridis', which is a colormap that transitions from yellow to green to blue.\n",
        "   - `yticklabels=False` removes the y-axis tick labels from the heatmap.\n",
        "\n",
        "- `plt.title('Missing value in the dataset')`\n",
        "   - This line sets the title of the plot as 'Missing value in the dataset' using the title function from matplotlib.pyplot.\n",
        "    It provides a descriptive title for the plot.\n",
        "\n",
        "The purpose of this code is to visually check for missing values in the 'df' DataFrame.\n",
        " The heatmap representation makes it easy to identify missing values as they are visually\n",
        "  distinguished from non-missing values. If there are missing values in the DataFrame,\n",
        "  the heatmap will show colored cells in the corresponding locations. In this case,\n",
        "  the heatmap indicates that there are no missing values in the 'df' DataFrame, as all cells are blank.\n",
        "\n",
        "The figure size, color map, and title settings are used to customize the appearance and informative value of the heatmap.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qPNaH_LBKOPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation plot\n",
        "#Thier no correlation among valiables.\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr, cmap = 'Wistia', annot= True);\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code you provided creates a correlation plot using the seaborn library. Here's a breakdown of each line:\n",
        "\n",
        "- `corr = df.corr()`\n",
        "   - This line calculates the correlation coefficients between the columns of\n",
        "    the 'df' DataFrame using the corr() method. The resulting correlation matrix is stored in the 'corr' variable.\n",
        "\n",
        "- `sns.heatmap(corr, cmap='Wistia', annot=True)`\n",
        "   - This line creates a heatmap to visualize the correlation matrix using the heatmap function from seaborn.\n",
        "   The correlation matrix ('corr') is passed as the input.\n",
        "   - `cmap='Wistia'` sets the color map to 'Wistia', which is a colormap with shades of yellow.\n",
        "   - `annot=True` adds numeric annotations to the heatmap, displaying the correlation coefficients on each cell.\n",
        "\n",
        "The purpose of this code is to visualize the correlation between the variables in the 'df' DataFrame.\n",
        " The heatmap provides a color-coded representation of the correlation matrix, where higher\n",
        " correlations are represented by brighter colors.\n",
        "\n",
        "By examining the heatmap, you can quickly identify patterns of correlation among the variables.\n",
        " Positive correlations are represented by colors tending towards yellow, while negative\n",
        " correlations are represented by colors tending towards blue. The numeric annotations provide the exact\n",
        " correlation coefficients.\n",
        "\n",
        "In this case, the code suggests that there are no strong correlations among the variables in the\n",
        "'df' DataFrame, as indicated by the lack of bright colors in the heatmap. This information can help\n",
        "in understanding the relationships between different variables and their potential impact on the target variable.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gS6ZFi1XNIDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f= plt.figure(figsize=(12,4))\n",
        "\n",
        "ax=f.add_subplot(121)\n",
        "sns.distplot(df['charges'],bins=50,color='r',ax=ax)\n",
        "ax.set_title('Distribution of insurance charges')\n",
        "\n",
        "ax=f.add_subplot(122)\n",
        "sns.distplot(np.log10(df['charges']),bins=40,color='b',ax=ax)\n",
        "ax.set_title('Distribution of insurance charges in\n",
        " sacle')\n",
        "ax.set_xscale('log');\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code you provided creates a figure with two subplots and plots the distributions of insurance charges\n",
        "in different scales. Here's a breakdown of each line:\n",
        "\n",
        "- `f = plt.figure(figsize=(12,4))`\n",
        "   - This line creates a figure object using the figure function from matplotlib.pyplot.\n",
        "    The figure size is set to (12,4) inches, specifying the width and height of the figure.\n",
        "\n",
        "- `ax = f.add_subplot(121)`\n",
        "   - This line adds a subplot to the figure using the add_subplot function from the figure object.\n",
        "    The subplot is positioned at location 121, indicating a 1x2 grid with the first position selected.\n",
        "\n",
        "- `sns.distplot(df['charges'], bins=50, color='r', ax=ax)`\n",
        "   - This line plots the distribution of the 'charges' variable from the 'df' DataFrame using the\n",
        "    distplot function from seaborn. The 'charges' column is selected from the DataFrame.\n",
        "   - `bins=50` specifies the number of bins to be used in the histogram.\n",
        "   - `color='r'` sets the color of the histogram bars to red.\n",
        "   - `ax=ax` specifies that the plot should be created in the previously defined subplot 'ax'.\n",
        "\n",
        "- `ax.set_title('Distribution of insurance charges')`\n",
        "   - This line sets the title of the first subplot as 'Distribution of insurance charges'\n",
        "    using the set_title function from the subplot 'ax'.\n",
        "\n",
        "- `ax = f.add_subplot(122)`\n",
        "   - This line adds a second subplot to the figure. The subplot is positioned at location 122,\n",
        "   indicating a 1x2 grid with the second position selected.\n",
        "\n",
        "- `sns.distplot(np.log10(df['charges']), bins=40, color='b', ax=ax)`\n",
        "   - This line plots the distribution of the logarithm (base 10) of the 'charges' variable using\n",
        "   the distplot function from seaborn. The 'charges' column from the 'df' DataFrame is transformed\n",
        "    using the np.log10 function before plotting.\n",
        "   - `bins=40` specifies the number of bins to be used in the histogram.\n",
        "   - `color='b'` sets the color of the histogram bars to blue.\n",
        "   - `ax=ax` specifies that the plot should be created in the second subplot 'ax'.\n",
        "\n",
        "- `ax.set_title('Distribution of insurance charges in scale')`\n",
        "   - This line sets the title of the second subplot as 'Distribution of insurance charges in scale'\n",
        "   using the set_title function from the subplot 'ax'.\n",
        "\n",
        "- `ax.set_xscale('log')`\n",
        "   - This line sets the x-axis scale of the second subplot to a logarithmic scale using the set_xscale\n",
        "   function from the subplot 'ax'. The logarithmic scale is applied to the x-axis only.\n",
        "\n",
        "The purpose of this code is to compare the distributions of insurance charges in their original scale\n",
        " and in a logarithmic scale. The first subplot shows the distribution of charges in the original scale,\n",
        "  while the second subplot displays the distribution of charges in a logarithmic scale. The logarithmic\n",
        "   scale can be useful for visualizing data with a wide range of values, as it compresses the scale and helps\n",
        "   reveal patterns in the lower values.\n",
        "\n",
        "By examining these two subplots, you can compare the shapes of the distributions and observe any differences or similarities.\n",
        "The titles of the subplots provide descriptive information about the data being plotted.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LXABZKJsNco7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**violinplot**"
      ],
      "metadata": {
        "id": "SO6VhIM4OqKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = plt.figure(figsize=(14,6))\n",
        "ax = f.add_subplot(121)\n",
        "sns.violinplot(x='sex', y='charges',data=df,palette='Wistia',ax=ax)\n",
        "ax.set_title('Violin plot of Charges vs sex')\n",
        "\n",
        "ax = f.add_subplot(122)\n",
        "sns.violinplot(x='smoker', y='charges',data=df,palette='magma',ax=ax)\n",
        "ax.set_title('Violin plot of Charges vs smoker');\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code you provided creates a figure with two subplots and plots violin plots to compare\n",
        "the distributions of charges based on different variables. Here's a breakdown of each line:\n",
        "\n",
        "- `f = plt.figure(figsize=(14,6))`\n",
        "   - This line creates a figure object with a size of (14,6) inches using the figure function\n",
        "    from matplotlib.pyplot. The figure size is specified as the width and height of the figure.\n",
        "\n",
        "- `ax = f.add_subplot(121)`\n",
        "   - This line adds a subplot to the figure at position 121, indicating a 1x2 grid with the first position selected.\n",
        "\n",
        "- `sns.violinplot(x='sex', y='charges', data=df, palette='Wistia', ax=ax)`\n",
        "   - This line plots a violin plot to compare the distributions of charges based on the 'sex' variable.\n",
        "   The data is obtained from the 'df' DataFrame.\n",
        "   - `x='sex'` specifies the variable to be plotted on the x-axis as 'sex'.\n",
        "   - `y='charges'` specifies the variable to be plotted on the y-axis as 'charges'.\n",
        "   - `data=df` specifies the DataFrame that contains the data.\n",
        "   - `palette='Wistia'` sets the color palette of the violin plot to 'Wistia', which is a colormap with shades of yellow.\n",
        "\n",
        "- `ax.set_title('Violin plot of Charges vs sex')`\n",
        "   - This line sets the title of the first subplot as 'Violin plot of Charges vs sex' using the\n",
        "   set_title function from the subplot 'ax'.\n",
        "\n",
        "- `ax = f.add_subplot(122)`\n",
        "   - This line adds a second subplot to the figure at position 122.\n",
        "\n",
        "- `sns.violinplot(x='smoker', y='charges', data=df, palette='magma', ax=ax)`\n",
        "   - This line plots another violin plot to compare the distributions of charges based on the 'smoker' variable.\n",
        "   - `x='smoker'` specifies the variable to be plotted on the x-axis as 'smoker'.\n",
        "   - `y='charges'` specifies the variable to be plotted on the y-axis as 'charges'.\n",
        "   - `data=df` specifies the DataFrame that contains the data.\n",
        "   - `palette='magma'` sets the color palette of the violin plot to 'magma', which is a colormap with\n",
        "      shades of red and purple.\n",
        "\n",
        "- `ax.set_title('Violin plot of Charges vs smoker')`\n",
        "   - This line sets the title of the second subplot as 'Violin plot of Charges vs smoker' using\n",
        "   the set_title function from the subplot 'ax'.\n",
        "\n",
        "The purpose of this code is to visually compare the distributions of charges based on the 'sex' and 'smoker'\n",
        "variables using violin plots.\n",
        "Violin plots display the distribution of data by showing the kernel density estimation on one side and\n",
        "a box plot on the other side.\n",
        "\n",
        "By examining these two subplots, you can compare the shapes of the distributions for different\n",
        "categories of the variables. The titles of the subplots provide descriptive information about the comparisons being made.\n",
        " The specified color palettes ('Wistia' and 'magma') are used to customize the color scheme of the violin plots.\n",
        " \"\"\"\n"
      ],
      "metadata": {
        "id": "sjsUarhYOH1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **boxplot**"
      ],
      "metadata": {
        "id": "W3VbJ7EgO8M2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,6))\n",
        "sns.boxplot(x='children', y='charges',hue='sex',data=df,palette='rainbow')\n",
        "plt.title('Box plot of charges vs children');\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code you provided creates a box plot to compare the charges based on the number of children\n",
        "and the sex of the individuals in the 'df' DataFrame. Here's a breakdown of each line:\n",
        "\n",
        "- `plt.figure(figsize=(14,6))`\n",
        "   - This line creates a new figure with a size of (14,6) inches using the figure function from matplotlib.pyplot.\n",
        "   The figure size is specified as the width and height of the figure.\n",
        "\n",
        "- `sns.boxplot(x='children', y='charges', hue='sex', data=df, palette='rainbow')`\n",
        "   - This line plots a box plot to compare the charges based on the number of children and the sex of the individuals.\n",
        "   - `x='children'` specifies the variable to be plotted on the x-axis as 'children', representing the number of children.\n",
        "   - `y='charges'` specifies the variable to be plotted on the y-axis as 'charges', representing the charges.\n",
        "   - `hue='sex'` specifies the variable to be used for grouping the data by sex. This creates separate box plots for each sex category.\n",
        "   - `data=df` specifies the DataFrame that contains the data.\n",
        "   - `palette='rainbow'` sets the color palette of the box plot to 'rainbow', which is a colormap with a range of colors.\n",
        "\n",
        "- `plt.title('Box plot of charges vs children')`\n",
        "   - This line sets the title of the plot as 'Box plot of charges vs children' using the title function from matplotlib.pyplot.\n",
        "    It provides a descriptive title for the plot.\n",
        "\n",
        "The purpose of this code is to visually compare the charges based on the number of children\n",
        "and the sex of the individuals using a box plot. The x-axis represents the number of children,\n",
        "the y-axis represents the charges, and the different box plots are grouped by the sex of the individuals.\n",
        "\n",
        "By examining the box plots, you can compare the distributions of charges for different categories of the number\n",
        " of children and sex. The boxes represent the interquartile range (IQR), the horizontal line within\n",
        " the box represents the median, and the whiskers represent the range of the data. The hue parameter\n",
        " allows for further differentiation of the box plots by the sex of the individuals.\n",
        "\n",
        "The title of the plot provides a concise description of the comparison being made.\n",
        " The specified color palette ('rainbow') is used to customize the color scheme of the box plot.\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "mXkoM13tOz2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KNzbXJjkQgTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**\n",
        "# **Encoding**"
      ],
      "metadata": {
        "id": "Sz6KpuKsQhLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy variable\n",
        "categorical_columns = ['sex','children', 'smoker', 'region']\n",
        "df_encode = pd.get_dummies(data = df, prefix = 'OHE', prefix_sep='_',\n",
        "               columns = categorical_columns,\n",
        "               drop_first =True,\n",
        "              dtype='int8')\n",
        "\n",
        "# Lets verify the dummay variable process\n",
        "print('Columns in original data frame:\\n',df.columns.values)\n",
        "print('\\nNumber of rows and columns in the dataset:',df.shape)\n",
        "print('\\nColumns in data frame after encoding dummy variable:\\n',df_encode.columns.values)\n",
        "print('\\nNumber of rows and columns in the dataset:',df_encode.shape)\n",
        "\n",
        "Columns in original data frame:\n",
        " ['age' 'sex' 'bmi' 'children' 'smoker' 'region' 'charges']\n",
        "\n",
        "Number of rows and columns in the dataset: (1338, 7)\n",
        "\n",
        "Columns in data frame after encoding dummy variable:\n",
        " ['age' 'bmi' 'charges' 'OHE_male' 'OHE_1' 'OHE_2' 'OHE_3' 'OHE_4' 'OHE_5'\n",
        " 'OHE_yes' 'OHE_northwest' 'OHE_southeast' 'OHE_southwest']\n",
        "\n",
        "Number of rows and columns in the dataset: (1338, 13)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code you provided performs one-hot encoding (also known as dummy variable encoding) on categorical\n",
        "columns in the 'df' DataFrame. Here's a breakdown of each line:\n",
        "\n",
        "- `categorical_columns = ['sex', 'children', 'smoker', 'region']`\n",
        "   - This line creates a list named 'categorical_columns' that contains the names of the categorical\n",
        "    columns in the 'df' DataFrame that you want to encode.\n",
        "\n",
        "- `df_encode = pd.get_dummies(data=df, prefix='OHE', prefix_sep='_', columns=categorical_columns,\n",
        " drop_first=True, dtype='int8')`\n",
        "   - This line applies one-hot encoding to the categorical columns in the 'df' DataFrame using\n",
        "   the get_dummies function from pandas.\n",
        "   - `data=df` specifies the DataFrame to encode.\n",
        "   - `prefix='OHE'` sets the prefix for the newly created dummy variable column names as 'OHE'.\n",
        "   - `prefix_sep='_'` specifies the separator to be used between the prefix and the original column name.\n",
        "   - `columns=categorical_columns` specifies the columns to encode using one-hot encoding, based on\n",
        "   the names provided in the 'categorical_columns' list.\n",
        "   - `drop_first=True` drops the first dummy variable column for each categorical column to\n",
        "   avoid multicollinearity issues. This is done because the dropped column can be inferred from the remaining columns.\n",
        "   - `dtype='int8'` sets the data type of the encoded dummy variables to 'int8',\n",
        "   which is a compact integer data type that saves memory.\n",
        "\n",
        "The purpose of this code is to transform the categorical columns in the 'df' DataFrame into numerical\n",
        " dummy variables using one-hot encoding. Each categorical column is replaced with multiple binary columns,\n",
        "  where each binary column represents a unique category within the original categorical column.\n",
        "   The prefix 'OHE' is added to the column names to indicate that they are one-hot encoded.\n",
        "\n",
        "The resulting DataFrame, 'df_encode', contains the original columns from 'df' along with\n",
        "the newly created dummy variable columns. The dummy variable columns are of integer type ('int8') and\n",
        "represent the presence or absence of a particular category within each categorical column.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "q47ZUhcwPWq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train-Test split**"
      ],
      "metadata": {
        "id": "of05Xjp6RHJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df_encode.drop('charges',axis=1) # Independet variable\n",
        "y = df_encode['charges'] # dependent variable\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=23)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code you provided performs data splitting using the train_test_split function from scikit-learn.\n",
        " Here's a breakdown of each line:\n",
        "\n",
        "- `from sklearn.model_selection import train_test_split`\n",
        "   - This line imports the train_test_split function from the model_selection module in scikit-learn.\n",
        "   The train_test_split function is used to split data into training and testing subsets.\n",
        "\n",
        "- `X = df_encode.drop('charges', axis=1)`\n",
        "   - This line assigns the independent variables to the 'X' variable by dropping the 'charges'\n",
        "   column from the 'df_encode' DataFrame using the drop function from pandas. The resulting DataFrame\n",
        "    contains all the columns except the 'charges' column.\n",
        "\n",
        "- `y = df_encode['charges']`\n",
        "   - This line assigns the dependent variable (the 'charges' column) to the 'y' variable.\n",
        "   It selects the 'charges' column from the 'df_encode' DataFrame.\n",
        "\n",
        "- `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=23)`\n",
        "   - This line splits the data into training and testing subsets using the train_test_split function.\n",
        "   - `X` and `y` are the arrays or DataFrames to be split.\n",
        "   - `test_size=0.3` specifies that 30% of the data will be used for testing, while 70% will be used for training.\n",
        "   - `random_state=23` sets the random seed for reproducibility, ensuring that the same random split is generated\n",
        "      each time the code is run.\n",
        "\n",
        "After running this code, you will have four sets of data: 'X_train' (training data for independent variables),\n",
        "'X_test' (testing data for independent variables), 'y_train' (training data for the dependent variable), and 'y_test'\n",
        " (testing data for the dependent variable). These datasets are split from the original 'df_encode' DataFrame based on\n",
        " the specified proportions, and they are ready to be used for model training and evaluation.\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "Yw8hx-uWP5bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Scikit Learn module\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train,y_train)\n",
        "\n",
        "# Finding interception and coefficients\n",
        "print(lin_reg.intercept_)\n",
        "print(list(lin_reg.coef_))\n",
        "\n",
        "-11738.954855430964\n",
        "[246.27260255058226]\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code you provided prints the intercept and coefficients of a linear regression model.\n",
        " Here's a breakdown of each line:\n",
        "\n",
        "- `print(lin_reg.intercept_)`\n",
        "   - This line prints the intercept of the linear regression model, which represents the value of the\n",
        "   dependent variable (y) when all independent variables (X) are zero. It uses the intercept_ attribute\n",
        "   of the linear regression model object (lin_reg).\n",
        "\n",
        "- `print(list(lin_reg.coef_))`\n",
        "   - This line prints the coefficients of the linear regression model, which represent the estimated\n",
        "   change in the dependent variable (y) associated with a one-unit change in each independent variable (X).\n",
        "    It uses the coef_ attribute of the linear regression model object (lin_reg).\n",
        "   - The coefficients are printed as a list.\n",
        "\n",
        "In the output you provided, the intercept of the linear regression model is approximately -11738.954855430964,\n",
        "and the coefficient for the independent variable is approximately 246.27260255058226.\n",
        "\n",
        "These values provide information about the relationship between the independent variable(s)\n",
        "and the dependent variable. The intercept indicates the baseline value of the dependent variable,\n",
        " while the coefficient represents the estimated change in the dependent variable associated with\n",
        " a one-unit change in the independent variable.\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "s_VaiwRFRjay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn regression module\n",
        "y_pred_sk = lin_reg.predict(X_test)\n",
        "\n",
        "#Evaluvation: MSE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "J_mse_sk = mean_squared_error(y_pred_sk, y_test)\n",
        "\n",
        "# R_square\n",
        "R_square_sk = lin_reg.score(X_test,y_test)\n",
        "print('The Mean Square Error(MSE) or J(theta) is: ',J_mse_sk)\n",
        "print('R square obtain for scikit learn library is :',R_square_sk)\n",
        "\n",
        "The Mean Square Error(MSE) or J(theta) is:  35152074.79986036\n",
        "R square obtain for scikit learn library is : 0.7305284299807451\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code you provided calculates the Mean Squared Error (MSE) and R-square values for the predictions made by\n",
        "a linear regression model using scikit-learn. Here's a breakdown of each line:\n",
        "\n",
        "- `y_pred_sk = lin_reg.predict(X_test)`\n",
        "   - This line uses the trained linear regression model (lin_reg) to predict the dependent variable (y)\n",
        "    for the testing dataset (X_test). The predicted values are stored in the 'y_pred_sk' variable.\n",
        "\n",
        "- `from sklearn.metrics import mean_squared_error`\n",
        "   - This line imports the mean_squared_error function from the metrics module in scikit-learn.\n",
        "    The mean_squared_error function is used to calculate the MSE between the predicted values and the true values.\n",
        "\n",
        "- `J_mse_sk = mean_squared_error(y_pred_sk, y_test)`\n",
        "   - This line calculates the MSE between the predicted values ('y_pred_sk') and\n",
        "   the true values of the dependent variable ('y_test'). The result is stored in the 'J_mse_sk' variable.\n",
        "\n",
        "- `R_square_sk = lin_reg.score(X_test, y_test)`\n",
        "   - This line calculates the R-square value of the linear regression model using the score method\n",
        "    of the trained model (lin_reg). The score method returns the coefficient of determination,\n",
        "\n",
        "    which represents the proportion of the variance in the dependent variable that is predictable\n",
        "    from the independent variables. The R-square value is stored in the 'R_square_sk' variable.\n",
        "\n",
        "- `print('The Mean Square Error(MSE) or J(theta) is: ', J_mse_sk)`\n",
        "   - This line prints the calculated MSE, which represents the average squared difference between\n",
        "    the predicted values and the true values of the dependent variable.\n",
        "\n",
        "- `print('R square obtain for scikit learn library is:', R_square_sk)`\n",
        "   - This line prints the R-square value, which represents the goodness-of-fit of the linear regression model.\n",
        "    It indicates the proportion of the variance in the dependent variable that can be explained by the independent variables.\n",
        "\n",
        "In the output you provided, the calculated MSE is approximately 35152074.79986036,\n",
        " and the R-square value is approximately 0.7305284299807451.\n",
        "\n",
        "These metrics provide a measure of the performance and fit of the linear regression model.\n",
        "The MSE represents the average squared difference between the predicted and true values,\n",
        "with lower values indicating better model performance. The R-square value ranges between 0 and 1,\n",
        "with higher values indicating better fit, where 1 represents a perfect fit.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "IyLvoNVwSV7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Mean Absolute Error**"
      ],
      "metadata": {
        "id": "JFnyELr-Tnll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python program for calculating Mean Absolute Error\n",
        "\n",
        "pip install scikit-learn\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "y_true = [3, -0.5, 2, 7]\n",
        "y_pred = [2.5, 0.0, 2, 8]\n",
        "MAE = mean_absolute_error(y_true, y_pred)\n",
        "print(MAE)\n",
        "\n",
        "\"\"\"\n",
        "The code you provided calculates the Mean Absolute Error (MAE) using scikit-learn. Here's a breakdown of each line:\n",
        "\n",
        "- `pip install scikit-learn`\n",
        "   - This line is used to install the scikit-learn library if it is not already installed.\n",
        "    It is a package that provides various machine learning algorithms and evaluation metrics.\n",
        "\n",
        "- `from sklearn.metrics import mean_absolute_error`\n",
        "   - This line imports the mean_absolute_error function from the metrics module in scikit-learn.\n",
        "    The mean_absolute_error function is used to calculate the MAE between the true values and the predicted values.\n",
        "\n",
        "- `y_true = [3, -0.5, 2, 7]`\n",
        "   - This line defines a list 'y_true' that contains the true values of the dependent variable.\n",
        "\n",
        "- `y_pred = [2.5, 0.0, 2, 8]`\n",
        "   - This line defines a list 'y_pred' that contains the predicted values of the dependent variable.\n",
        "\n",
        "- `MAE = mean_absolute_error(y_true, y_pred)`\n",
        "   - This line calculates the MAE between the true values ('y_true') and the predicted values ('y_pred')\n",
        "    using the mean_absolute_error function. The result is stored in the 'MAE' variable.\n",
        "\n",
        "- `print(MAE)`\n",
        "   - This line prints the calculated MAE, which represents the average absolute difference\n",
        "   between the true values and the predicted values.\n",
        "\n",
        "In the output, the calculated MAE is 0.5. This means that, on average, the predicted values\n",
        " differ from the true values by 0.5. The MAE is a measure of the average absolute error and\n",
        "  provides a straightforward evaluation of the accuracy of the predictions.\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "AkOvFti9Tkj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **max error**"
      ],
      "metadata": {
        "id": "1pTe7x9nVMZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required module\n",
        "from sklearn.metrics import max_error\n",
        "\n",
        "# Assign data\n",
        "y_true = [6, 2, 5, 1]\n",
        "y_pred = [4, 2, 7, 1]\n",
        "\n",
        "# Compute max_error\n",
        "print(max_error(y_true, y_pred))\n",
        "\n",
        "\"\"\"\n",
        "The code you provided calculates the maximum error between the true values and the\n",
        "predicted values using the max_error function from scikit-learn. Here's a breakdown of each line:\n",
        "\n",
        "- `from sklearn.metrics import max_error`\n",
        "   - This line imports the max_error function from the metrics module in scikit-learn.\n",
        "   The max_error function is used to calculate the maximum error between two sets of values.\n",
        "\n",
        "- `y_true = [6, 2, 5, 1]`\n",
        "   - This line defines a list 'y_true' that contains the true values of the dependent variable.\n",
        "\n",
        "- `y_pred = [4, 2, 7, 1]`\n",
        "   - This line defines a list 'y_pred' that contains the predicted values of the dependent variable.\n",
        "\n",
        "- `print(max_error(y_true, y_pred))`\n",
        "   - This line calculates the maximum error between the true values ('y_true') and\n",
        "   the predicted values ('y_pred') using the max_error function. The result is printed using the print function.\n",
        "\n",
        "In the output, the calculated maximum error is 2. This means that the maximum difference between\n",
        " any true value and its corresponding predicted value is 2. The max_error metric provides\n",
        " a measure of the worst-case error between the true and predicted values, highlighting the largest discrepancy between the two sets of values.\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "ss4cyTZeVJCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "### Assume y is the actual value and f is the predicted values\n",
        "y =[10, 20, 30]\n",
        "f =[10, 20, 30]\n",
        "r2 = r2_score(y, f)\n",
        "print('r2 score for perfect model is', r2)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code you provided calculates the R-squared (coefficient of determination) score between the actual values ('y') and\n",
        "the predicted values ('f') using the r2_score function from scikit-learn. Here's a breakdown of each line:\n",
        "\n",
        "- `from sklearn.metrics import r2_score`\n",
        "   - This line imports the r2_score function from the metrics module in scikit-learn.\n",
        "    The r2_score function is used to calculate the R-squared score, which measures the goodness-of-fit of a model.\n",
        "\n",
        "- `y = [10, 20, 30]`\n",
        "   - This line defines a list 'y' that contains the actual (true) values.\n",
        "\n",
        "- `f = [10, 20, 30]`\n",
        "   - This line defines a list 'f' that contains the predicted values.\n",
        "\n",
        "- `r2 = r2_score(y, f)`\n",
        "   - This line calculates the R-squared score between the actual values ('y') and the predicted values ('f')\n",
        "   using the r2_score function. The result is stored in the 'r2' variable.\n",
        "\n",
        "- `print('r2 score for perfect model is', r2)`\n",
        "   - This line prints the calculated R-squared score, which measures the proportion of\n",
        "   the variance in the dependent variable that is predictable from the independent variable(s).\n",
        "\n",
        "In the output, the calculated R-squared score is 1. This means that the predicted values perfectly match the actual values,\n",
        " and the model explains 100% of the variance in the dependent variable. The R-squared score ranges\n",
        " between 0 and 1, where 1 represents a perfect fit.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "t6fTbJGgVi5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **r-square and adjusted r-square**"
      ],
      "metadata": {
        "id": "pPUCbiw_YdfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Download dataset and add complete path of the dataset.\n",
        "# Importing dataset\n",
        "s = pd.read_csv('Salary_Data.csv')\n",
        "\n",
        "\n",
        "# Used to standardise statsmodel in python\n",
        "f = np.ones((30, 1))\n",
        "s.insert(0, 'extra', f)\n",
        "\n",
        "# Gives summary of data model->gives value of r-square and adjusted r-square\n",
        "import statsmodels.formula.api as sm\n",
        "X_opt = s.iloc[:, :-1]\n",
        "Y1 = s.iloc[:, -1]\n",
        "\n",
        "\n",
        "regressor_OLS = sm.OLS(endog = Y1, exog = X_opt).fit()\n",
        "regressor_OLS.summary()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code you provided performs multiple steps for data manipulation, model building,\n",
        " and model summary using the statsmodels library. Here's a breakdown of each section:\n",
        "\n",
        "1. Importing necessary libraries:\n",
        "   - `import pandas as pd` imports the pandas library for data manipulation.\n",
        "   - `import numpy as np` imports the numpy library for numerical operations.\n",
        "\n",
        "2. Downloading and importing the dataset:\n",
        "   - `s = pd.read_csv('Salary_Data.csv')` reads the dataset from a CSV file named\n",
        "   'Salary_Data.csv' and assigns it to the 's' variable.\n",
        "\n",
        "3. Adding a column of ones:\n",
        "   - `f = np.ones((30, 1))` creates a 30x1 array of ones using the numpy ones function and assigns it to the 'f' variable.\n",
        "   - `s.insert(0, 'extra', f)` inserts the 'extra' column with the array of ones at the beginning\n",
        "   of the 's' DataFrame using the insert function from pandas. This is typically done\n",
        "   to incorporate the intercept term in the regression model.\n",
        "\n",
        "4. Model fitting and summary:\n",
        "   - `import statsmodels.formula.api as sm` imports the statsmodels library for regression modeling.\n",
        "   - `X_opt = s.iloc[:, :-1]` selects all columns except the last one (independent variables) from\n",
        "   the 's' DataFrame and assigns them to the 'X_opt' variable.\n",
        "   - `Y1 = s.iloc[:, -1]` selects the last column (dependent variable) from the 's' DataFrame and assigns it to the 'Y1' variable.\n",
        "   - `regressor_OLS = sm.OLS(endog=Y1, exog=X_opt).fit()` fits the ordinary least squares (OLS)\n",
        "   regression model using the OLS function from statsmodels. The dependent variable is specified\n",
        "    as 'Y1', and the independent variables are specified as 'X_opt'.\n",
        "   - `regressor_OLS.summary()` displays the summary of the OLS regression model, including statistical\n",
        "    measures like R-squared, adjusted R-squared, coefficients, standard errors, p-values, etc.\n",
        "\n",
        "The purpose of this code is to perform a linear regression analysis on the 'Salary_Data.csv' dataset.\n",
        " The 'extra' column is added as an intercept term, and the OLS regression model is fitted using\n",
        "  the independent variables in 'X_opt' and the dependent variable in 'Y1'. The 'regressor_OLS.summary()'\n",
        "   statement generates a summary table that provides detailed information about the model's statistical measures and coefficients.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The output of regressor_OLS.summary() provides a detailed summary of the linear regression model.\n",
        "Here's an explanation of the important statistics:\n",
        "\n",
        "OLS Regression Results: This section provides an overview of the regression results,\n",
        "including the model name, dependent variable, model degrees of freedom, residuals degrees of freedom,\n",
        " and the method used for estimation.\n",
        "\n",
        "R-squared and Adj. R-squared: These statistics indicate the goodness-of-fit of the model.\n",
        "The R-squared value represents the proportion of the variance in the dependent variable\n",
        " that is explained by the independent variables. The adjusted R-squared adjusts the R-squared value\n",
        "  for the number of predictors in the model.\n",
        "\n",
        "coef column: This column displays the estimated coefficients (slope) for each independent variable.\n",
        "The 'extra' column represents the intercept term.\n",
        "\n",
        "std err column: This column displays the standard errors of the estimated coefficients.\n",
        " It indicates the precision of the coefficient estimates.\n",
        "\n",
        "t and P>|t| columns: These columns provide the t-statistic and the corresponding p-value for each coefficient.\n",
        " The t-statistic measures the significance of each coefficient, and the p-value represents\n",
        "  the probability of observing the coefficient value if the null hypothesis (no relationship) is true.\n",
        "  Lower p-values indicate more significant coefficients.\n",
        "\n",
        "Omnibus, Prob(Omnibus), Skew, Kurtosis: These statistics provide information about the residuals'\n",
        " normality assumption. The Omnibus test examines the skewness and kurtosis of the residuals,\n",
        " and the Prob(Omnibus) value represents the probability of the residuals being normally distributed.\n",
        " The Skewness and Kurtosis values indicate the deviation from the normal distribution.\n",
        "\n",
        "Durbin-Watson: This statistic tests for the presence of autocorrelation (correlation of residuals) in the model.\n",
        " The value ranges between 0 and 4, and a value around 2 suggests no autocorrelation.\n",
        "\n",
        "Jarque-Bera: This statistic tests for normality in the residuals.\n",
        " A significant Jarque-Bera value indicates a departure from the normal distribution assumption.\n",
        "\n",
        "Cond. No.: This statistic measures multicollinearity among the independent variables.\n",
        " A higher condition number suggests stronger multicollinearity.\n",
        "\n",
        "The summary output provides a comprehensive overview of the linear regression model,\n",
        " including information about the model's fit, coefficients, statistical significance, and assumptions.\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "snb1T54eXXAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate scatter plot of independent vs Dependent variable\n",
        "plt.style.use('ggplot')\n",
        "fig = plt.figure(figsize = (18, 18))\n",
        "\n",
        "for index, feature_name in enumerate(boston_dataset.feature_names):\n",
        "\tax = fig.add_subplot(4, 4, index + 1)\n",
        "\tax.scatter(boston_dataset.data[:, index], boston_dataset.target)\n",
        "\tax.set_ylabel('House Price', size = 12)\n",
        "\tax.set_xlabel(feature_name, size = 12)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "The code you provided generates scatter plots of each independent variable against\n",
        "the dependent variable ('House Price') using the Boston Housing dataset. Here's a breakdown of each line:\n",
        "\n",
        "- `plt.style.use('ggplot')`\n",
        "   - This line sets the style of the plot to 'ggplot', which is a popular style for data visualization.\n",
        "\n",
        "- `fig = plt.figure(figsize = (18, 18))`\n",
        "   - This line creates a new figure with a specified size of 18x18 inches using the figure function from matplotlib.pyplot.\n",
        "   The 'fig' variable represents the entire figure.\n",
        "\n",
        "- `for index, feature_name in enumerate(boston_dataset.feature_names):`\n",
        "   - This line initiates a loop over the indices and feature names of\n",
        "   the independent variables in the Boston Housing dataset. The 'enumerate' function is used to retrieve\n",
        "   both the index and the corresponding feature name.\n",
        "\n",
        "- `ax = fig.add_subplot(4, 4, index + 1)`\n",
        "   - This line adds a subplot to the figure at the specified position in a 4x4 grid.\n",
        "   The 'index + 1' is used to increment the subplot position.\n",
        "\n",
        "- `ax.scatter(boston_dataset.data[:, index], boston_dataset.target)`\n",
        "   - This line creates a scatter plot by plotting the values of the independent variable (boston_dataset.data[:, index])\n",
        "   on the x-axis and the corresponding house prices (boston_dataset.target)\n",
        "   on the y-axis. 'boston_dataset.data' represents the independent variables, and 'boston_dataset.target'\n",
        "   represents the dependent variable.\n",
        "\n",
        "- `ax.set_ylabel('House Price', size = 12)`\n",
        "   - This line sets the label for the y-axis as 'House Price'.\n",
        "\n",
        "- `ax.set_xlabel(feature_name, size = 12)`\n",
        "   - This line sets the label for the x-axis as the corresponding feature name of the independent variable.\n",
        "\n",
        "- `plt.show()`\n",
        "   - This line displays the figure with all the scatter plots.\n",
        "The code generates a grid of scatter plots, where each plot represents the relationship\n",
        "between one independent variable and the dependent variable. The x-axis shows the values of\n",
        " the independent variable, and the y-axis shows the corresponding house prices. By visualizing\n",
        " the scatter plots, you can gain insights into the relationship between each independent variable and the\n",
        " house prices in the Boston Housing dataset."
      ],
      "metadata": {
        "id": "-0vXvVOyYobL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into Pandas Dataframe\n",
        "boston_pd = pd.DataFrame(boston_dataset.data)\n",
        "\n",
        "boston_pd.columns = boston_dataset.feature_names\n",
        "boston_pd_target = np.asarray(boston_dataset.target)\n",
        "\n",
        "boston_pd['House Price'] = pd.Series(boston_pd_target)\n",
        "\n",
        "# input\n",
        "X = boston_pd.iloc[:, :-1]\n",
        "\n",
        "#output\n",
        "Y = boston_pd.iloc[:, -1]\n",
        "\n",
        "print(boston_pd.head())\n",
        "\n",
        "\"\"\"\n",
        "The code you provided performs the following steps:\n",
        "\n",
        "1. Creating a DataFrame from the Boston Housing dataset:\n",
        "   - `boston_pd = pd.DataFrame(boston_dataset.data)` creates a DataFrame 'boston_pd'\n",
        "   from the data part of the Boston Housing dataset.\n",
        "\n",
        "2. Assigning column names to the DataFrame:\n",
        "   - `boston_pd.columns = boston_dataset.feature_names` assigns the feature names\n",
        "   from the Boston Housing dataset as column names in the 'boston_pd' DataFrame.\n",
        "\n",
        "3. Adding the target variable to the DataFrame:\n",
        "   - `boston_pd_target = np.asarray(boston_dataset.target)` converts the target variable\n",
        "   from the Boston Housing dataset into a numpy array.\n",
        "   - `boston_pd['House Price'] = pd.Series(boston_pd_target)` adds the target variable as\n",
        "   a new column named 'House Price' to the 'boston_pd' DataFrame using the Series function from pandas.\n",
        "\n",
        "\n",
        "Certainly! Let's break down the code step by step:\n",
        "\n",
        "X = boston_pd.iloc[:, :-1]: This line selects all rows (denoted by :) of the boston_pd DataFrame\n",
        "   and all columns except the last one (denoted by :-1). This means that X will contain the input or\n",
        "   independent variables of the dataset. Each row represents an instance or data point,\n",
        "   and each column represents a different input variable.\n",
        "\n",
        "Y = boston_pd.iloc[:, -1]: This line selects all rows of the boston_pd DataFrame\n",
        "  and only the last column (denoted by -1). This means that Y will contain the output or\n",
        "  dependent variable of the dataset. The dependent variable represents the target\n",
        "   or response variable that we want to predict or explain.\n",
        "\n",
        "\n",
        "\n",
        "5. Printing the head of the DataFrame:\n",
        "   - `print(boston_pd.head())` displays the first few rows of the 'boston_pd' DataFrame,\n",
        "   showing the input variables (independent variables) and the output variable (dependent variable) together.\n",
        "\n",
        "The code creates a DataFrame 'boston_pd' that combines the independent variables from\n",
        "the Boston Housing dataset with the target variable ('House Price').\n",
        "It then assigns the input variable 'X' as all columns except the last one and the output variable 'Y' as the last column.\n",
        "Finally, it prints the first few rows of the DataFrame to show the structure of the dataset.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "P28ztdpBa8hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "\tboston_pd.iloc[:, :-1], boston_pd.iloc[:, -1],\n",
        "\ttest_size = 0.25)\n",
        "\n",
        "print(\"Train data shape of X = % s and Y = % s : \"%(\n",
        "\tx_train.shape, y_train.shape))\n",
        "\n",
        "print(\"Test data shape of X = % s and Y = % s : \"%(\n",
        "\tx_test.shape, y_test.shape))\n",
        "\n",
        "\n",
        "Train data shape of X = (379, 13) and Y = (379,) :\n",
        "Test data shape of X = (127, 13) and Y = (127,) :\n",
        "\n",
        "\"\"\"\n",
        "The code you provided performs the train-test split on the Boston Housing dataset using\n",
        "the `train_test_split` function from scikit-learn. Here's an explanation of the code and the printed output:\n",
        "\n",
        "1. `train_test_split` function:\n",
        "   - `train_test_split` is a function from scikit-learn's `model_selection` module that\n",
        "    splits the dataset into training and testing subsets.\n",
        "   - The function takes two main arguments: the input variables (independent variables)\n",
        "      and the output variable (dependent variable).\n",
        "   - Additional arguments can be provided, such as `test_size` to specify\n",
        "      the proportion of the dataset to be allocated for testing.\n",
        "\n",
        "2. `x_train, x_test, y_train, y_test = train_test_split(boston_pd.iloc[:, :-1],\n",
        "\n",
        "     boston_pd.iloc[:, -1], test_size=0.25)`: This line splits the Boston Housing dataset into training and testing sets, where:\n",
        "   - `x_train` and `x_test` contain the input variables (independent variables) for training and testing, respectively.\n",
        "   - `y_train` and `y_test` contain the output variable (dependent variable) for training and testing, respectively.\n",
        "   - `boston_pd.iloc[:, :-1]` selects all columns except the last one as the input variables.\n",
        "   - `boston_pd.iloc[:, -1]` selects only the last column as the output variable.\n",
        "\n",
        "3. Printing the shapes of the train and test data:\n",
        "   - `print(\"Train data shape of X = % s and Y = % s : \"%(x_train.shape, y_train.shape))`\n",
        "     prints the shape (number of rows and columns) of the training data, where `x_train.shape`\n",
        "     represents the shape of the input variables for training and `y_train.shape` represents\n",
        "      the shape of the output variable for training.\n",
        "   - `print(\"Test data shape of X = % s and Y = % s : \"%(x_test.shape, y_test.shape))`\n",
        "     prints the shape of the test data, where `x_test.shape` represents the shape of the input\n",
        "      variables for testing and `y_test.shape` represents the shape of the output variable for testing.\n",
        "\n",
        "The printed output shows the number of rows and columns in the training and testing sets. In this case:\n",
        "- The training set has 379 rows and 13 columns, indicating that there are 379 instances\n",
        "  for training, and the input variables have 13 features.\n",
        "- The testing set has 127 rows and 13 columns, indicating that there are 127 instances\n",
        "  for testing, and the input variables have 13 features.\n",
        "\n",
        "  This train-test split is commonly used in machine learning to separate the data into training and testing subsets,\n",
        "  allowing the model to be trained on a portion of the data and evaluated on unseen data to assess its performance.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XBitrqGxb524"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multiple (Linear) Regression**"
      ],
      "metadata": {
        "id": "HEyWRyc7dvS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply multiple Linear Regression Model\n",
        "lreg = LinearRegression()\n",
        "lreg.fit(x_train, y_train)\n",
        "\n",
        "# Generate Prediction on test set\n",
        "lreg_y_pred = lreg.predict(x_test)\n",
        "\n",
        "# calculating Mean Squared Error (mse)\n",
        "mean_squared_error = np.mean((lreg_y_pred - y_test)**2)\n",
        "print(\"Mean squared Error on test set : \", mean_squared_error)\n",
        "\n",
        "# Putting together the coefficient and their corresponding variable names\n",
        "lreg_coefficient = pd.DataFrame()\n",
        "lreg_coefficient[\"Columns\"] = x_train.columns\n",
        "lreg_coefficient['Coefficient Estimate'] = pd.Series(lreg.coef_)\n",
        "print(lreg_coefficient)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The code you provided applies a multiple linear regression model to the training data,\n",
        " generates predictions on the test set, calculates the mean squared error (MSE) on the test set,\n",
        " and prints the coefficient estimates of the model. Here's a breakdown of each section:\n",
        "\n",
        "1. Multiple Linear Regression Model:\n",
        "   - `lreg = LinearRegression()` initializes a linear regression model object using\n",
        "    the `LinearRegression` class from scikit-learn.\n",
        "   - `lreg.fit(x_train, y_train)` fits the linear regression model to the training data,\n",
        "   where `x_train` represents the input variables for training, and `y_train` represents the output variable for training.\n",
        "\n",
        "2. Generating Predictions on the Test Set:\n",
        "   - `lreg_y_pred = lreg.predict(x_test)` generates predictions on the test set using the trained linear regression model.\n",
        "   `x_test` represents the input variables for testing.\n",
        "\n",
        "3. Calculating Mean Squared Error (MSE) on the Test Set:\n",
        "   - `mean_squared_error = np.mean((lreg_y_pred - y_test)**2)` calculates the mean squared error (MSE)\n",
        "    between the predicted values (`lreg_y_pred`) and the actual values (`y_test`) of the output variable on the test set.\n",
        "\n",
        "4. Printing the Mean Squared Error (MSE):\n",
        "   - `print(\"Mean squared Error on test set : \", mean_squared_error)` prints the calculated mean squared error on the test set.\n",
        "\n",
        "5. Coefficient Estimates:\n",
        "   - `lreg_coefficient = pd.DataFrame()` creates an empty DataFrame to store the coefficient estimates.\n",
        "   - `lreg_coefficient[\"Columns\"] = x_train.columns` assigns the column names of the input variables\n",
        "   to the \"Columns\" column of the `lreg_coefficient` DataFrame.\n",
        "   - `lreg_coefficient['Coefficient Estimate'] = pd.Series(lreg.coef_)` assigns the coefficient estimates\n",
        "   of the linear regression model to the \"Coefficient Estimate\" column of the `lreg_coefficient` DataFrame.\n",
        "   - `print(lreg_coefficient)` prints the coefficient estimates and their corresponding variable names.\n",
        "\n",
        "The output of this code will be the mean squared error on the test set and the coefficient estimates\n",
        "of the linear regression model. The coefficient estimates provide information about the relationship\n",
        "between the input variables and the output variable. Each row in the output represents a different\n",
        "input variable, and the \"Coefficient Estimate\" column shows the corresponding coefficient value.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "output:-\n",
        "          The output shows the results of the multiple linear regression model:\n",
        "\n",
        "1. Mean squared error on the test set: The mean squared error (MSE) on the test set is 21.16849927899985.\n",
        "  This value represents the average squared difference between the predicted values and the actual\n",
        "  values of the output variable\n",
        "  (House Price) on the test set. A lower MSE indicates a better fit of the model to the test data.\n",
        "\n",
        "2. Coefficient estimates:\n",
        "   - Column 0: CRIM (per capita crime rate): The coefficient estimate for the CRIM variable is -0.088226.\n",
        "   This suggests that, on average, for every unit increase in the per capita crime rate,\n",
        "   the predicted house price decreases by 0.088226 units, all other variables being held constant.\n",
        "   - Column 1: ZN (proportion of residential land zoned for lots over 25,000 sq.ft.):\n",
        "   The coefficient estimate for the ZN variable is 0.037623. This indicates that, on average,\n",
        "   for every unit increase in the proportion of residential land zoned for large lots,\n",
        "    the predicted house price increases by 0.037623 units, all other variables being held constant.\n",
        "\n",
        "The coefficient estimates provide insights into the relationship between the input variables and the output variable.\n",
        " Positive coefficients indicate a positive relationship (an increase in the variable leads\n",
        " to an increase in the predicted house price),\n",
        " while negative coefficients indicate a negative relationship (an increase in the variable leads to\n",
        " a decrease in the predicted house price). However, it's important to interpret these coefficients in\n",
        "  the context of the specific dataset and consider other factors and statistical tests for a comprehensive analysis.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UZry7UFEdkRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize =(20, 10))\n",
        "\n",
        "color =['tab:gray', 'tab:blue', 'tab:orange',\n",
        "'tab:green', 'tab:red', 'tab:purple', 'tab:brown',\n",
        "'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan',\n",
        "'tab:orange', 'tab:green', 'tab:blue', 'tab:olive']\n",
        "\n",
        "ax.bar(lreg_coefficient[\"Columns\"],\n",
        "lreg_coefficient['Coefficient Estimate'],\n",
        "color = color)\n",
        "\n",
        "ax.spines['bottom'].set_position('zero')\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "The code provided creates a bar plot to visualize the coefficient estimates of the multiple linear regression model.\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "1. `fig, ax = plt.subplots(figsize=(20, 10))`: This line creates a figure and axis object with\n",
        " a specified figsize (figure size) of 20x10 inches. The `fig` variable represents the entire figure,\n",
        " and the `ax` variable represents the axis object.\n",
        "\n",
        "2. `color = ['tab:gray', 'tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple',\n",
        "'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan', 'tab:orange', 'tab:green', 'tab:blue', 'tab:olive']`:\n",
        "This line creates a list of colors to be used for each bar in the bar plot. Each color corresponds to a different independent variable.\n",
        "\n",
        "3. `ax.bar(lreg_coefficient[\"Columns\"], lreg_coefficient['Coefficient Estimate'], color=color)`:\n",
        "   This line creates the bar plot using the `bar` function from matplotlib.pyplot. It plots the coefficient estimates\n",
        " (`lreg_coefficient['Coefficient Estimate']`) on the y-axis against the corresponding independent variable names\n",
        " (`lreg_coefficient[\"Columns\"]`) on the x-axis. The `color` argument specifies the color for each bar based on the `color` list.\n",
        "\n",
        "4. `ax.spines['bottom'].set_position('zero')`: This line sets the position of the bottom spine (x-axis) to zero.\n",
        "    This ensures that the x-axis is placed at the zero position on the y-axis.\n",
        "\n",
        "5. `plt.style.use('ggplot')`: This line sets the style of the plot to 'ggplot', which is a popular style for data visualization.\n",
        "\n",
        "6. `plt.show()`: This line displays the bar plot.\n",
        "\n",
        "The resulting bar plot visualizes the coefficient estimates of the multiple linear regression model.\n",
        "Each bar represents an independent variable, and its height represents the corresponding coefficient estimate.\n",
        "The colors are used to differentiate between the bars representing different independent variables.\n",
        "This plot provides a visual representation of the relative magnitudes and directions of the effects of\n",
        "the independent variables on the dependent variable.\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "L5zTkN5nfxJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ridge Regression:**"
      ],
      "metadata": {
        "id": "ENy4jS-Wg1L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import ridge regression from sklearn library\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Train the model\n",
        "ridgeR = Ridge(alpha = 1)\n",
        "ridgeR.fit(x_train, y_train)\n",
        "y_pred = ridgeR.predict(x_test)\n",
        "\n",
        "# calculate mean square error\n",
        "mean_squared_error_ridge = np.mean((y_pred - y_test)**2)\n",
        "print(mean_squared_error_ridge)\n",
        "\n",
        "# get ridge coefficient and print them\n",
        "ridge_coefficient = pd.DataFrame()\n",
        "ridge_coefficient[\"Columns\"]= x_train.columns\n",
        "ridge_coefficient['Coefficient Estimate'] = pd.Series(ridgeR.coef_)\n",
        "print(ridge_coefficient)\n",
        "\n",
        "\n",
        "21.85660946502666\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Certainly! Let's go through the code step by step:\n",
        "\n",
        "1. Importing Ridge regression:\n",
        "   - `from sklearn.linear_model import Ridge` imports the Ridge regression class from the linear_model module of scikit-learn.\n",
        "   Ridge regression is a linear regression technique that incorporates L2 regularization to prevent overfitting.\n",
        "\n",
        "2. Training the Ridge regression model:\n",
        "   - `ridgeR = Ridge(alpha=1)` initializes a Ridge regression model object with an alpha value of 1.\n",
        "   The alpha parameter controls the regularization strength, where higher values of alpha result in stronger regularization.\n",
        "   - `ridgeR.fit(x_train, y_train)` fits the Ridge regression model to the training data. `x_train` represents\n",
        "   the input variables for training, and `y_train` represents the output variable for training.\n",
        "    The model learns the relationship between the input variables and the output variable during this training process.\n",
        "\n",
        "3. Generating predictions on the test set:\n",
        "   - `y_pred = ridgeR.predict(x_test)` generates predictions on the test set using the trained Ridge regression model.\n",
        "    `x_test` represents the input variables for testing.\n",
        "\n",
        "4. Calculating the mean squared error (MSE):\n",
        "   - `mean_squared_error_ridge = np.mean((y_pred - y_test)**2)` calculates the mean squared error (MSE)\n",
        "    between the predicted values (`y_pred`) and the actual values (`y_test`) of the output variable on the test set.\n",
        "     MSE measures the average squared difference between the predicted and actual values, providing an indication of the model's performance.\n",
        "\n",
        "5. Printing the mean squared error (MSE):\n",
        "   - `print(mean_squared_error_ridge)` prints the calculated mean squared error on the test set,\n",
        "   which quantifies the prediction accuracy of the Ridge regression model. A lower MSE indicates better performance.\n",
        "\n",
        "6. Coefficient estimates:\n",
        "   - `ridge_coefficient = pd.DataFrame()` creates an empty DataFrame to store the coefficient estimates of the Ridge regression model.\n",
        "   - `ridge_coefficient[\"Columns\"] = x_train.columns` assigns the column names of the input variables\n",
        "    to the \"Columns\" column of the `ridge_coefficient` DataFrame.\n",
        "   - `ridge_coefficient['Coefficient Estimate'] = pd.Series(ridgeR.coef_)` assigns the coefficient estimates of\n",
        "    the Ridge regression model to the \"Coefficient Estimate\" column of the `ridge_coefficient` DataFrame.\n",
        "    These coefficients represent the estimated impact of each input variable on the output variable.\n",
        "   - `print(ridge_coefficient)` prints the coefficient estimates and their corresponding variable names,\n",
        "    providing insights into the relationship between the input variables and the output variable.\n",
        "\n",
        "The output of this code will be the mean squared error (MSE) on the test set,\n",
        "representing the prediction accuracy of the Ridge regression model. Additionally, the coefficient estimates are printed,\n",
        "indicating the relative importance and impact of the input variables on the output variable.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pVy94RGTh1At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **lasso regression**"
      ],
      "metadata": {
        "id": "QZjX8DURlwiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import Lasso regression from sklearn library\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# Train the model\n",
        "lasso = Lasso(alpha = 1)\n",
        "lasso.fit(x_train, y_train)\n",
        "y_pred1 = lasso.predict(x_test)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mean_squared_error = np.mean((y_pred1 - y_test)**2)\n",
        "print(\"Mean squared error on test set\", mean_squared_error)\n",
        "lasso_coeff = pd.DataFrame()\n",
        "lasso_coeff[\"Columns\"] = x_train.columns\n",
        "lasso_coeff['Coefficient Estimate'] = pd.Series(lasso.coef_)\n",
        "\n",
        "print(lasso_coeff)"
      ],
      "metadata": {
        "id": "FZHSbwP_l6uC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **#ElasticNet :**"
      ],
      "metadata": {
        "id": "bBmPuoGziVhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import model\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# Train the model\n",
        "e_net = ElasticNet(alpha = 1)\n",
        "e_net.fit(x_train, y_train)\n",
        "\n",
        "# calculate the prediction and mean square error\n",
        "y_pred_elastic = e_net.predict(x_test)\n",
        "mean_squared_error = np.mean((y_pred_elastic - y_test)**2)\n",
        "print(\"Mean Squared Error on test set\", mean_squared_error)\n",
        "\n",
        "e_net_coeff = pd.DataFrame()\n",
        "e_net_coeff[\"Columns\"] = x_train.columns\n",
        "e_net_coeff['Coefficient Estimate'] = pd.Series(e_net.coef_)\n",
        "e_net_coeff\n",
        "\n",
        "\n",
        "Mean Squared Error on test set 24.153095177606172\n",
        "Columns\tCoefficient Estimate\n",
        "0\tCRIM\t-0.074705\n",
        "1\tZN\t0.043621\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Sure! Let's go through the code step by step:\n",
        "\n",
        "1. Importing ElasticNet regression:\n",
        "   - `from sklearn.linear_model import ElasticNet` imports the ElasticNet regression class from the linear_model module\n",
        "    of scikit-learn. ElasticNet regression combines L1 and L2 regularization to strike a balance between\n",
        "    feature selection and coefficient shrinkage.\n",
        "\n",
        "2. Training the ElasticNet regression model:\n",
        "   - `e_net = ElasticNet(alpha=1)` initializes an ElasticNet regression model object with an alpha value of 1.\n",
        "   The alpha parameter controls the regularization strength, where higher values of\n",
        "    alpha result in stronger regularization.\n",
        "   - `e_net.fit(x_train, y_train)` fits the ElasticNet regression model to the training data.\n",
        "   `x_train` represents the input variables for training, and `y_train` represents the output variable for training.\n",
        "    The model learns the relationship between the input variables and the output variable during this training process.\n",
        "\n",
        "3. Generating predictions on the test set:\n",
        "   - `y_pred_elastic = e_net.predict(x_test)` generates predictions on the test set using\n",
        "   the trained ElasticNet regression model. `x_test` represents the input variables for testing.\n",
        "\n",
        "4. Calculating the mean squared error (MSE):\n",
        "   - `mean_squared_error = np.mean((y_pred_elastic - y_test)**2)` calculates\n",
        "    the mean squared error (MSE) between the predicted values (`y_pred_elastic`) and\n",
        "    the actual values (`y_test`) of the output variable on the test set. MSE measures\n",
        "     the average squared difference between the predicted and actual values, providing an indication of the model's performance.\n",
        "\n",
        "5. Printing the mean squared error (MSE):\n",
        "   - `print(\"Mean Squared Error on test set\", mean_squared_error)` prints\n",
        "   the calculated mean squared error on the test set, which quantifies\n",
        "   the prediction accuracy of the ElasticNet regression model. A lower MSE indicates better performance.\n",
        "\n",
        "6. Coefficient estimates:\n",
        "\n",
        "   - `e_net_coeff = pd.DataFrame()` creates an empty DataFrame to store\n",
        "   the coefficient estimates of the ElasticNet regression model.\n",
        "   - `e_net_coeff[\"Columns\"] = x_train.columns` assigns the column names of\n",
        "   the input variables to the \"Columns\" column of the `e_net_coeff` DataFrame.\n",
        "\n",
        "   - `e_net_coeff['Coefficient Estimate'] = pd.Series(e_net.coef_)` assigns\n",
        "   the coefficient estimates of the ElasticNet regression model to the \"Coefficient Estimate\"\n",
        "   column of the `e_net_coeff` DataFrame. These coefficients represent the estimated\n",
        "    impact of each input variable on the output variable.\n",
        "\n",
        "   - `e_net_coeff` prints the DataFrame containing the coefficient estimates and their corresponding variable names.\n",
        "\n",
        "The output of this code will be the mean squared error (MSE) on the test set, representing\n",
        "the prediction accuracy of the ElasticNet regression model. Additionally, the coefficient estimates are printed,\n",
        "indicating the relative importance and impact of the input variables on the output variable.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "weN2frnUiUpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# import the iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "# splitting X and y into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "\tX, y, test_size=0.3, random_state=1)\n",
        "# GAUSSIAN NAIVE BAYES\n",
        "gnb = GaussianNB()\n",
        "# train the model\n",
        "gnb.fit(X_train, y_train)\n",
        "# make predictions\n",
        "gnb_pred = gnb.predict(X_test)\n",
        "# print the accuracy\n",
        "print(\"Accuracy of Gaussian Naive Bayes: \", accuracy_score(y_test, gnb_pred))\n",
        "\n",
        "# DECISION TREE CLASSIFIER\n",
        "dt = DecisionTreeClassifier(random_state=0)\n",
        "# train the model\n",
        "dt.fit(X_train, y_train)\n",
        "# make predictions\n",
        "dt_pred = dt.predict(X_test)\n",
        "# print the accuracy\n",
        "print(\"Accuracy of Decision Tree Classifier: \", accuracy_score(y_test, dt_pred))\n",
        "\n",
        "# SUPPORT VECTOR MACHINE\n",
        "svm_clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "# train the model\n",
        "svm_clf.fit(X_train, y_train)\n",
        "# make predictions\n",
        "svm_clf_pred = svm_clf.predict(X_test)\n",
        "# print the accuracy\n",
        "print(\"Accuracy of Support Vector Machine: \",\n",
        "\taccuracy_score(y_test, svm_clf_pred))\n",
        "\n",
        "Accuracy of Gaussian Naive Bayes:  0.9333333333333333\n",
        "Accuracy of Decision Tree Classifier:  0.9555555555555556\n",
        "Accuracy of Support Vector Machine:  1.0\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "In this code, three different classification algorithms are trained and evaluated\n",
        "on the iris dataset. Here's an explanation of each section:\n",
        "\n",
        "1. Gaussian Naive Bayes (GNB):\n",
        "   - `gnb = GaussianNB()` initializes a Gaussian Naive Bayes classifier object.\n",
        "   - `gnb.fit(X_train, y_train)` trains the GNB classifier on the training data.\n",
        "   - `gnb_pred = gnb.predict(X_test)` makes predictions on the testing data using\n",
        "   the trained GNB classifier.\n",
        "   - `accuracy_score(y_test, gnb_pred)` calculates the accuracy of the GNB classifier\n",
        "      by comparing the predicted labels (`gnb_pred`) with the true labels (`y_test`).\n",
        "   - `print(\"Accuracy of Gaussian Naive Bayes: \", accuracy_score(y_test, gnb_pred))`\n",
        "   prints the accuracy score of the GNB classifier.\n",
        "\n",
        "2. Decision Tree Classifier (DT):\n",
        "   - `dt = DecisionTreeClassifier(random_state=0)` initializes a Decision Tree classifier\n",
        "    object with a random state of 0.\n",
        "   - `dt.fit(X_train, y_train)` trains the DT classifier on the training data.\n",
        "   - `dt_pred = dt.predict(X_test)` makes predictions on the testing data using the trained DT classifier.\n",
        "   - `accuracy_score(y_test, dt_pred)` calculates the accuracy of the DT classifier\n",
        "     by comparing the predicted labels (`dt_pred`) with the true labels (`y_test`).\n",
        "   - `print(\"Accuracy of Decision Tree Classifier: \", accuracy_score(y_test, dt_pred))`\n",
        "    prints the accuracy score of the DT classifier.\n",
        "\n",
        "3. Support Vector Machine (SVM):\n",
        "   - `svm_clf = svm.SVC(kernel='linear')` initializes a Support Vector Machine classifier\n",
        "      object with a linear kernel.\n",
        "   - `svm_clf.fit(X_train, y_train)` trains the SVM classifier on the training data.\n",
        "   - `svm_clf_pred = svm_clf.predict(X_test)` makes predictions on the testing data using\n",
        "      the trained SVM classifier.\n",
        "   - `accuracy_score(y_test, svm_clf_pred)` calculates the accuracy of the SVM classifier\n",
        "      by comparing the predicted labels (`svm_clf_pred`) with the true labels (`y_test`).\n",
        "   - `print(\"Accuracy of Support Vector Machine: \", accuracy_score(y_test, svm_clf_pred))`\n",
        "      prints the accuracy score of the SVM classifier.\n",
        "\n",
        "The output of this code will be the accuracy scores of the Gaussian Naive Bayes, Decision Tree Classifier,\n",
        "and Support Vector Machine models on the iris dataset. The accuracy score represents the percentage of\n",
        "correctly predicted labels in the testing data. A higher accuracy score indicates better performance.\n",
        "In this case, the SVM model achieves a perfect accuracy of 1.0, indicating that it correctly predicts\n",
        "all the labels in the testing data. The GNB model has an accuracy of 0.933, and the DT model has an\n",
        "accuracy of 0.956, both performing well but slightly lower than the SVM model.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-mAfaAT_l-Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NVbhNA-for3V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}